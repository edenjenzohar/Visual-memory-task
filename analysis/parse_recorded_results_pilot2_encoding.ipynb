{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import pathlib as path\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from PIL import Image\n",
    "from random import sample\n",
    "from cmath import nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch found c:\\Users\\d_abe\\Desktop\\human similarity database\\edens github repo\\Visual-memory-task\\data\\pilot_24_hours\\batch 1\n",
      "Data folder found c:\\Users\\d_abe\\Desktop\\human similarity database\\edens github repo\\Visual-memory-task\\data\\pilot_24_hours\\batch 1\\data\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_name='batch 1'\n",
    "\n",
    "qualification_name_for_testin='UPDATE-eligible for next step memory rep'\n",
    "qualification_name_for_entire_experiment='UPDATE-completed memory rep'\n",
    "\n",
    "#all data location is relational to the location of this jupiter notebook:\n",
    "batch_data_location=path.Path.cwd().parent\n",
    "batch_data_location = batch_data_location / 'data' / 'pilot_24_hours' \n",
    "\n",
    "\n",
    "if (batch_data_location / batch_name).is_dir():\n",
    "    batch_data_location= batch_data_location / batch_name\n",
    "    print('Batch found',batch_data_location)\n",
    "else: \n",
    "    print(f'PROBLEM FOUND: the requested batch name {batch_name} does not apear in the folder: {batch_data_location}')\n",
    "\n",
    "\n",
    "PATH_TO_DATA = batch_data_location / 'data'\n",
    "if not PATH_TO_DATA.exists():\n",
    "    print('There is no data folder in the requested location',batch_data_location / 'data')\n",
    "else: \n",
    "    print('Data folder found',batch_data_location / 'data')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paste the shelf here: \n",
    "shelf_dict={\n",
    "  \"A2KDZLWD8RAHDM\": [\n",
    "    999,\n",
    "    999\n",
    "  ],\n",
    "  \"AABZGLZ5QWCG0\": [\n",
    "    999,\n",
    "    999,\n",
    "    999\n",
    "  ],\n",
    "  \"A2I6HVUDBTGD1\": [\n",
    "    999,\n",
    "    999\n",
    "  ],\n",
    "  \"A248QG4DPULP46\": [\n",
    "    2,\n",
    "    1666796745860,\n",
    "    1666875548743\n",
    "  ],\n",
    "  \"ANGJEGCCP3AO2\": [\n",
    "    999,\n",
    "    999\n",
    "  ],\n",
    "  \"A2LHZMUV3Q81X0\": [\n",
    "    999,\n",
    "    999\n",
    "  ],\n",
    "  \"A3CFG3M2O22KYQ\": [\n",
    "    999,\n",
    "    999\n",
    "  ],\n",
    "  \"A33C0ZCZH9CZKA\": [\n",
    "    999,\n",
    "    999\n",
    "  ],\n",
    "  \"A1JJYY622DGE5L\": [\n",
    "    999,\n",
    "    1666798289847\n",
    "  ],\n",
    "  \"A2ASR7XQA7KERU\": [\n",
    "    999,\n",
    "    1666798330693\n",
    "  ],\n",
    "  \"A1618RA11ZOD8Y\": [\n",
    "    999,\n",
    "    999\n",
    "  ],\n",
    "  \"A1XMGLCK09Z0DW\": [\n",
    "    999,\n",
    "    999,\n",
    "    999\n",
    "  ],\n",
    "  \"AAECD8RBWBLU9\": [\n",
    "    999,\n",
    "    999,\n",
    "    999\n",
    "  ],\n",
    "  \"ACA2RL31B2G57\": [\n",
    "    999,\n",
    "    999\n",
    "  ],\n",
    "  \"AM27MWA9NUQQH\": [\n",
    "    999,\n",
    "    999\n",
    "  ],\n",
    "  \"A1D5QV7YAPIC30\": [\n",
    "    999,\n",
    "    999,\n",
    "    999\n",
    "  ],\n",
    "  \"A1K4RESK1XUMQA\": [\n",
    "    999,\n",
    "    999\n",
    "  ],\n",
    "  \"AIYQVOLW7CF3Z\": [\n",
    "    999,\n",
    "    999\n",
    "  ],\n",
    "  \"A34J6WUTOV16M1\": [\n",
    "    999,\n",
    "    999\n",
    "  ],\n",
    "  \"A13THDIE8LTQ11\": [\n",
    "    999,\n",
    "    999\n",
    "  ],\n",
    "  \"A2RS15DB7NDYIF\": [\n",
    "    999,\n",
    "    1666802624130\n",
    "  ],\n",
    "  \"A32FHGV347AF6M\": [\n",
    "    999,\n",
    "    999\n",
    "  ],\n",
    "  \"A26F7OWQB4H0CH\": [\n",
    "    999,\n",
    "    1666803549164\n",
    "  ],\n",
    "  \"A22HIX1M4QXZBB\": [\n",
    "    19,\n",
    "    1666804285762,\n",
    "    1666882028114\n",
    "  ],\n",
    "  \"A244N987STMI0V\": [\n",
    "    999,\n",
    "    999\n",
    "  ],\n",
    "  \"A1Q3GFQXJMIHQ8\": [\n",
    "    999,\n",
    "    999,\n",
    "    999\n",
    "  ],\n",
    "  \"A36CTSMHOB5YN9\": [\n",
    "    999,\n",
    "    999\n",
    "  ],\n",
    "  \"A2J1DNVMJ56JG1\": [\n",
    "    22,\n",
    "    1666806879557,\n",
    "    1666887012627\n",
    "  ],\n",
    "  \"A3EUH97BRHRSI6\": [\n",
    "    999,\n",
    "    999\n",
    "  ],\n",
    "  \"A2Y69684WT44XU\": [\n",
    "    999,\n",
    "    1666808929934\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this section reads all the relevant files: \n",
    "if (batch_data_location / 'Batch_encoding_batch_results.csv').exists():\n",
    "    encoding_df=pd.read_csv(batch_data_location / 'Batch_encoding_batch_results.csv')\n",
    "else: \n",
    "    print(f'no \"Batch_encoding_batch_results.csv\" was found in data')\n",
    "\n",
    "if (batch_data_location / 'Batch_testing_batch_results.csv').exists():\n",
    "    testing_df=pd.read_csv(batch_data_location / 'Batch_testing_batch_results.csv')\n",
    "else: \n",
    "    print(f'no \"Batch_testing_batch_results.csv\" was found in data (probably because only the encoding session finished)')\n",
    "if (batch_data_location / 'Batch_workers.csv').exists():\n",
    "    workers_df=pd.read_csv(batch_data_location / 'Batch_workers.csv')\n",
    "else:\n",
    "    print('No AMAZON worker list was found: please make sure to upload one and name it correctly')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_largest_consequtive_repetition(responses_array):\n",
    "#add a stop value so the loop will use the logic also if the end of the responses is all repeating: \n",
    "    responses_array=np.append(responses_array,[99])\n",
    "    longest_rep_dict=dict()\n",
    "    last_input=responses_array[0]\n",
    "    consequtive_rep_counter=0\n",
    "    for response in responses_array[1:]: \n",
    "        if response==last_input: #if consequtive rep: \n",
    "            consequtive_rep_counter=consequtive_rep_counter+1 #add to counter\n",
    "        else: #once a new entry is in the vector - store the counter rep information \n",
    "            if last_input in longest_rep_dict.keys(): #if it was allready stored in our dictionary\n",
    "                if longest_rep_dict[last_input]<consequtive_rep_counter: #replace the counter only if it is higher than what stored in dict\n",
    "                    longest_rep_dict[last_input]=consequtive_rep_counter\n",
    "            else: #this entry is not yet in the dictionary: add it \n",
    "                longest_rep_dict[last_input]=consequtive_rep_counter\n",
    "            \n",
    "            consequtive_rep_counter=0\n",
    "            last_input=response\n",
    "    return max(longest_rep_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_worker_results(PATH_TO_BATCH,subject_name):\n",
    "    cur_sub=pd.read_csv(PATH_TO_BATCH / subject_name)\n",
    "    sub_demographics=cur_sub[['workID','Age','Gender']].iloc[0]\n",
    "\n",
    "    #extract demo related information: \n",
    "\n",
    "    #if participant did not click on the arrow during the demo a 'demo_encoding_response.rt' colmumn wont exists: \n",
    "    #thus we will create one and fill it with nans (so everything will be consistent with other participants)\n",
    "    if not('demo_encoding_response.rt' in cur_sub.columns):\n",
    "        cur_sub['demo_encoding_response.rt']=np.nan\n",
    "    demo_columns=['demo_encoding_loop.thisTrialN','DemoImage','DemoCorrect','demo_encoding_response.rt','demo_encoding_response.keys']\n",
    "\n",
    "    sub_demo_information=cur_sub[demo_columns]\n",
    "    empty_inds=sub_demo_information.loc[sub_demo_information.isnull().apply(lambda x: all(x), axis=1)].index\n",
    "    #drop irrelevant columns: \n",
    "    sub_demo_information=sub_demo_information.drop(index=empty_inds)\n",
    "\n",
    "\n",
    "    #extract the demo test columns: \n",
    "    demo_test_columns=['demo_test_response.keys','demo_test_response.corr','demo_test_response.rt','demo_test_loop.thisTrialN','DemoImage1','DemoImage2','DemoCorrectTest']\n",
    "    sub_demo_test_information=cur_sub[demo_test_columns]\n",
    "    empty_inds=sub_demo_test_information.loc[sub_demo_test_information.isnull().apply(lambda x: all(x), axis=1)].index\n",
    "    #drop irrelevant columns: \n",
    "    sub_demo_test_information=sub_demo_test_information.drop(index=empty_inds)\n",
    "\n",
    "    demo_df=pd.concat([sub_demo_information.reset_index(),sub_demo_test_information.reset_index()],axis=1)\n",
    "\n",
    "    #extract real experiment related information: \n",
    "\n",
    "    #if participant did not click on the arrow during the encoding a 'test_encoding_response.rt' column wont exists: \n",
    "    #thus we will create one and fill it with nans (so everything will be consistent with other participants)\n",
    "    if not('test_encoding_response.rt' in cur_sub.columns):\n",
    "        cur_sub['test_encoding_response.rt']=np.nan\n",
    "\n",
    "\n",
    "    encoding_related_columns=['test_encoding_response.keys','test_encoding_response.corr','trials.thisTrialN','target_image','pair','layer','correct','test_encoding_response.rt','key_resp_end.keys']\n",
    "    sub_encoding_information=cur_sub[encoding_related_columns]\n",
    "    #encoding section ends with a key press of the space key: so seperate this phase by finding this space key row\n",
    "    end_of_section_ind=np.where(sub_encoding_information['key_resp_end.keys']=='space')[0][0]\n",
    "    sub_encoding_information=sub_encoding_information.iloc[0:end_of_section_ind]\n",
    "    #remove all the rows that precede the real encoding phase: \n",
    "    empty_inds=sub_encoding_information.loc[sub_encoding_information.isnull().apply(lambda x: all(x), axis=1)].index\n",
    "    sub_encoding_information=sub_encoding_information.drop(index=empty_inds).reset_index()\n",
    "\n",
    "    #extract real experiment TEST related information: \n",
    "    #test_related_columns=['layer','correct','test_test_response.keys','test_test_response.corr','test_test_response.rt','trials_2.thisRepN','trials_2.thisTrialN','trials_2.thisN','trials_2.thisIndex','trials_2.ran','image1','image2']\n",
    "    #sub_test_information=cur_sub[test_related_columns].iloc[end_of_section_ind+2:-1]\n",
    "\n",
    "\n",
    "    subject_dictionary=dict()\n",
    "    subject_dictionary['demographics']=sub_demographics\n",
    "    subject_dictionary['demo_df']=demo_df\n",
    "    subject_dictionary['encoding_df']=sub_encoding_information\n",
    "    #subject_dictionary['test_df']=sub_test_information\n",
    "\n",
    "    return subject_dictionary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current csv files: [WindowsPath('c:/Users/d_abe/Desktop/human similarity database/edens github repo/Visual-memory-task/data/pilot_24_hours/batch 1/data/ENCODING_A1618RA11ZOD8Y_2022-10-26_11h33.42.790.csv'), WindowsPath('c:/Users/d_abe/Desktop/human similarity database/edens github repo/Visual-memory-task/data/pilot_24_hours/batch 1/data/ENCODING_A1JJYY622DGE5L_2022-10-26_11h31.29.847.csv'), WindowsPath('c:/Users/d_abe/Desktop/human similarity database/edens github repo/Visual-memory-task/data/pilot_24_hours/batch 1/data/ENCODING_A22HIX1M4QXZBB_2022-10-26_13h11.25.762.csv'), WindowsPath('c:/Users/d_abe/Desktop/human similarity database/edens github repo/Visual-memory-task/data/pilot_24_hours/batch 1/data/ENCODING_A244N987STMI0V_2022-10-26_13h16.54.309.csv'), WindowsPath('c:/Users/d_abe/Desktop/human similarity database/edens github repo/Visual-memory-task/data/pilot_24_hours/batch 1/data/ENCODING_A248QG4DPULP46_2022-10-26_11h05.45.860.csv'), WindowsPath('c:/Users/d_abe/Desktop/human similarity database/edens github repo/Visual-memory-task/data/pilot_24_hours/batch 1/data/ENCODING_A26F7OWQB4H0CH_2022-10-26_12h59.09.164.csv'), WindowsPath('c:/Users/d_abe/Desktop/human similarity database/edens github repo/Visual-memory-task/data/pilot_24_hours/batch 1/data/ENCODING_A2ASR7XQA7KERU_2022-10-26_11h32.10.693.csv'), WindowsPath('c:/Users/d_abe/Desktop/human similarity database/edens github repo/Visual-memory-task/data/pilot_24_hours/batch 1/data/ENCODING_A2I6HVUDBTGD1_2022-10-26_11h00.24.223.csv'), WindowsPath('c:/Users/d_abe/Desktop/human similarity database/edens github repo/Visual-memory-task/data/pilot_24_hours/batch 1/data/ENCODING_A2J1DNVMJ56JG1_2022-10-26_13h54.39.557.csv'), WindowsPath('c:/Users/d_abe/Desktop/human similarity database/edens github repo/Visual-memory-task/data/pilot_24_hours/batch 1/data/ENCODING_A2LHZMUV3Q81X0_2022-10-26_11h15.19.450.csv'), WindowsPath('c:/Users/d_abe/Desktop/human similarity database/edens github repo/Visual-memory-task/data/pilot_24_hours/batch 1/data/ENCODING_A2RS15DB7NDYIF_2022-10-26_12h43.44.130.csv'), WindowsPath('c:/Users/d_abe/Desktop/human similarity database/edens github repo/Visual-memory-task/data/pilot_24_hours/batch 1/data/ENCODING_A2Y69684WT44XU_2022-10-26_14h28.49.934.csv')]\n"
     ]
    }
   ],
   "source": [
    "all_filenames=[file for file in PATH_TO_DATA.iterdir() if 'csv' in file.name and 'ENCODING' in file.name]\n",
    "print('current csv files:',all_filenames)\n",
    "\n",
    "qualification_for_test_df=pd.DataFrame(columns=['workerID','arrow_acc','mean_arrow_RT'])\n",
    "for subject_csv in all_filenames:\n",
    "    subject_dict=process_worker_results(PATH_TO_DATA,path.Path(subject_csv))\n",
    "    cur_sub_encoding=subject_dict['encoding_df']\n",
    "\n",
    "    sname=subject_csv.name.split('_')[1] #change according to actuall format. \n",
    "\n",
    "    #get only attention check related info: \n",
    "    cur_sub_encoding=cur_sub_encoding[['test_encoding_response.keys','correct','test_encoding_response.rt']].copy().dropna(how = 'all')\n",
    "    if len(cur_sub_encoding)==0: #empty - the participant didnt respond on the arrow at all\n",
    "        arrow_acc=0\n",
    "        RT=nan\n",
    "    else: \n",
    "        RT=cur_sub_encoding['test_encoding_response.rt'].mean()\n",
    "        arrow_acc=(cur_sub_encoding['correct']==cur_sub_encoding['test_encoding_response.keys']).mean()\n",
    "    sub_df=pd.DataFrame({'workerID':sname,'arrow_acc':arrow_acc,'mean_arrow_RT':RT},index=[sname])\n",
    "    qualification_for_test_df=pd.concat([qualification_for_test_df,sub_df],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "qualification_for_test_df['in_encoding_workers_list']=nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "for curr_worker_ID in qualification_for_test_df.index:\n",
    "    if curr_worker_ID in encoding_df['WorkerId'].values:\n",
    "        qualification_for_test_df.loc[curr_worker_ID,'in_encoding_workers_list']=int(1)\n",
    "    else:\n",
    "        qualification_for_test_df.loc[curr_worker_ID,'in_encoding_workers_list']=int(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workerID</th>\n",
       "      <th>arrow_acc</th>\n",
       "      <th>mean_arrow_RT</th>\n",
       "      <th>in_encoding_workers_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A22HIX1M4QXZBB</th>\n",
       "      <td>A22HIX1M4QXZBB</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.69246</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A248QG4DPULP46</th>\n",
       "      <td>A248QG4DPULP46</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.53968</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A26F7OWQB4H0CH</th>\n",
       "      <td>A26F7OWQB4H0CH</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.16346</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2ASR7XQA7KERU</th>\n",
       "      <td>A2ASR7XQA7KERU</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.60104</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2J1DNVMJ56JG1</th>\n",
       "      <td>A2J1DNVMJ56JG1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.296075</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2Y69684WT44XU</th>\n",
       "      <td>A2Y69684WT44XU</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.562533</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      workerID arrow_acc mean_arrow_RT  \\\n",
       "A22HIX1M4QXZBB  A22HIX1M4QXZBB       1.0       0.69246   \n",
       "A248QG4DPULP46  A248QG4DPULP46       1.0       0.53968   \n",
       "A26F7OWQB4H0CH  A26F7OWQB4H0CH       0.6       0.16346   \n",
       "A2ASR7XQA7KERU  A2ASR7XQA7KERU       1.0       1.60104   \n",
       "A2J1DNVMJ56JG1  A2J1DNVMJ56JG1       0.8      1.296075   \n",
       "A2Y69684WT44XU  A2Y69684WT44XU       0.6      1.562533   \n",
       "\n",
       "                in_encoding_workers_list  \n",
       "A22HIX1M4QXZBB                       1.0  \n",
       "A248QG4DPULP46                       1.0  \n",
       "A26F7OWQB4H0CH                       1.0  \n",
       "A2ASR7XQA7KERU                       1.0  \n",
       "A2J1DNVMJ56JG1                       1.0  \n",
       "A2Y69684WT44XU                       1.0  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qualified_df=qualification_for_test_df.loc[(qualification_for_test_df['arrow_acc']>=0.6) & (qualification_for_test_df['in_encoding_workers_list']==1),:]\n",
    "qualified_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workerID</th>\n",
       "      <th>arrow_acc</th>\n",
       "      <th>mean_arrow_RT</th>\n",
       "      <th>in_encoding_workers_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A1618RA11ZOD8Y</th>\n",
       "      <td>A1618RA11ZOD8Y</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.952</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1JJYY622DGE5L</th>\n",
       "      <td>A1JJYY622DGE5L</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8464</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A244N987STMI0V</th>\n",
       "      <td>A244N987STMI0V</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.368833</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2I6HVUDBTGD1</th>\n",
       "      <td>A2I6HVUDBTGD1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2LHZMUV3Q81X0</th>\n",
       "      <td>A2LHZMUV3Q81X0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.60784</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2RS15DB7NDYIF</th>\n",
       "      <td>A2RS15DB7NDYIF</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.137033</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      workerID arrow_acc mean_arrow_RT  \\\n",
       "A1618RA11ZOD8Y  A1618RA11ZOD8Y       0.2         0.952   \n",
       "A1JJYY622DGE5L  A1JJYY622DGE5L       1.0        0.8464   \n",
       "A244N987STMI0V  A244N987STMI0V       0.4      0.368833   \n",
       "A2I6HVUDBTGD1    A2I6HVUDBTGD1       0.0           NaN   \n",
       "A2LHZMUV3Q81X0  A2LHZMUV3Q81X0       0.4       0.60784   \n",
       "A2RS15DB7NDYIF  A2RS15DB7NDYIF       0.6      2.137033   \n",
       "\n",
       "                in_encoding_workers_list  \n",
       "A1618RA11ZOD8Y                       1.0  \n",
       "A1JJYY622DGE5L                       0.0  \n",
       "A244N987STMI0V                       0.0  \n",
       "A2I6HVUDBTGD1                        1.0  \n",
       "A2LHZMUV3Q81X0                       0.0  \n",
       "A2RS15DB7NDYIF                       0.0  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disqualified_df=qualification_for_test_df.loc[(qualification_for_test_df['arrow_acc']<0.6) | (qualification_for_test_df['in_encoding_workers_list']==0),:]\n",
    "disqualified_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "these are all participants that will be updated in the workers list:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Worker ID</th>\n",
       "      <th>UPDATE-eligible for next step memory rep</th>\n",
       "      <th>UPDATE-completed memory rep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>A22HIX1M4QXZBB</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>A248QG4DPULP46</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>A26F7OWQB4H0CH</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>A2ASR7XQA7KERU</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>A2J1DNVMJ56JG1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>A2Y69684WT44XU</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>A1618RA11ZOD8Y</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>A2I6HVUDBTGD1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Worker ID  UPDATE-eligible for next step memory rep  \\\n",
       "554   A22HIX1M4QXZBB                                       1.0   \n",
       "585   A248QG4DPULP46                                       1.0   \n",
       "617   A26F7OWQB4H0CH                                       1.0   \n",
       "684   A2ASR7XQA7KERU                                       1.0   \n",
       "809   A2J1DNVMJ56JG1                                       1.0   \n",
       "1008  A2Y69684WT44XU                                       1.0   \n",
       "86    A1618RA11ZOD8Y                                       1.0   \n",
       "791    A2I6HVUDBTGD1                                       1.0   \n",
       "\n",
       "      UPDATE-completed memory rep  \n",
       "554                           NaN  \n",
       "585                           NaN  \n",
       "617                           NaN  \n",
       "684                           NaN  \n",
       "809                           NaN  \n",
       "1008                          NaN  \n",
       "86                            1.0  \n",
       "791                           1.0  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#update the workers list with the relevant qualification: \n",
    "#add the qualification for all eligible participants for the test session: \n",
    "ind_in_workers_df=[]\n",
    "for worker_id in qualified_df.index: \n",
    "    if worker_id in workers_df['Worker ID'].values:\n",
    "        workers_df.loc[workers_df['Worker ID']==worker_id,qualification_name_for_testin]=1\n",
    "        ind_in_workers_df.append(workers_df.loc[workers_df['Worker ID']==worker_id,qualification_name_for_testin].index[0])\n",
    "#remove from experiment all those that disqualified (so they wont be able to take the test session): \n",
    "for worker_id in disqualified_df.index: \n",
    "    if worker_id in workers_df['Worker ID'].values:\n",
    "        workers_df.loc[workers_df['Worker ID']==worker_id,qualification_name_for_entire_experiment]=1\n",
    "        ind_in_workers_df.append(workers_df.loc[workers_df['Worker ID']==worker_id,qualification_name_for_entire_experiment].index[0])\n",
    "\n",
    "#print the two relevant columns of the updated workers_list: \n",
    "print('these are all participants that will be updated in the workers list:')\n",
    "workers_df.loc[ind_in_workers_df,['Worker ID',qualification_name_for_testin,qualification_name_for_entire_experiment]]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the worker list to upload (to update the qualifications)\n",
    "workers_df.to_csv(batch_data_location/'Batch_workers_for_upload.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A2KDZLWD8RAHDM': [999, 999],\n",
       " 'AABZGLZ5QWCG0': [999, 999, 999],\n",
       " 'A2I6HVUDBTGD1': [999, 999],\n",
       " 'A248QG4DPULP46': [2, 1666796745860, 1666875548743],\n",
       " 'ANGJEGCCP3AO2': [999, 999],\n",
       " 'A2LHZMUV3Q81X0': [999, 999],\n",
       " 'A3CFG3M2O22KYQ': [999, 999],\n",
       " 'A33C0ZCZH9CZKA': [999, 999],\n",
       " 'A1JJYY622DGE5L': [999, 1666798289847],\n",
       " 'A2ASR7XQA7KERU': [999, 1666798330693],\n",
       " 'A1618RA11ZOD8Y': [999, 999],\n",
       " 'A1XMGLCK09Z0DW': [999, 999, 999],\n",
       " 'AAECD8RBWBLU9': [999, 999, 999],\n",
       " 'ACA2RL31B2G57': [999, 999],\n",
       " 'AM27MWA9NUQQH': [999, 999],\n",
       " 'A1D5QV7YAPIC30': [999, 999, 999],\n",
       " 'A1K4RESK1XUMQA': [999, 999],\n",
       " 'AIYQVOLW7CF3Z': [999, 999],\n",
       " 'A34J6WUTOV16M1': [999, 999],\n",
       " 'A13THDIE8LTQ11': [999, 999],\n",
       " 'A2RS15DB7NDYIF': [999, 1666802624130],\n",
       " 'A32FHGV347AF6M': [999, 999],\n",
       " 'A26F7OWQB4H0CH': [999, 1666803549164],\n",
       " 'A22HIX1M4QXZBB': [19, 1666804285762, 1666882028114],\n",
       " 'A244N987STMI0V': [999, 999],\n",
       " 'A1Q3GFQXJMIHQ8': [999, 999, 999],\n",
       " 'A36CTSMHOB5YN9': [999, 999],\n",
       " 'A2J1DNVMJ56JG1': [22, 1666806879557, 1666887012627],\n",
       " 'A3EUH97BRHRSI6': [999, 999],\n",
       " 'A2Y69684WT44XU': [999, 1666808929934]}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key in shelf_dict.keys():\n",
    "    cur_entries=shelf_dict[key]\n",
    "    if len(cur_entries)==2:\n",
    "       cur_entries[0]=999\n",
    "\n",
    "    shelf_dict\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('my_env_v3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "682fd5356c59e6193a7b57b256db50cf61987195eaf98c0915436170dbde729d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
