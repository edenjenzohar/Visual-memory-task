{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import pathlib as path\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from PIL import Image\n",
    "from random import sample\n",
    "from cmath import nan\n",
    "import json\n",
    "\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch found c:\\Users\\User\\Desktop\\visualpilot2\\Visual-memory-task\\data\\pilot_24_hours\\batch 3\n",
      "Data folder found c:\\Users\\User\\Desktop\\visualpilot2\\Visual-memory-task\\data\\pilot_24_hours\\batch 3\\data\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_name='batch 3' #batch name - make sure the folder is structured as followes: (the test results/data doesnt have to be there)\n",
    "\n",
    "#parent name: \n",
    "# -pilot_24_hours: \n",
    "#   -batch name (folder)\n",
    "#       -data (folder)\n",
    "#       -Batch_encoding_batch_results.csv \n",
    "#       -Batch_testing_batch_results.csv \n",
    "#       -Batch_workers.csv\n",
    "#       -Batch_workers_after_test.csv\n",
    "\n",
    "\n",
    "qualification_name_for_testin='UPDATE-eligible for next step memory rep'  #note that the -space- after the title is improtant as for some reason this is how the qualification name is defined\n",
    "qualification_name_for_entire_experiment='UPDATE-completed memory rep'\n",
    "\n",
    "#all data location is relational to the location of this jupiter notebook:\n",
    "batch_data_location=path.Path.cwd().parent\n",
    "batch_data_location = batch_data_location / 'data' / 'pilot_24_hours' \n",
    "\n",
    "\n",
    "if (batch_data_location / batch_name).is_dir():\n",
    "    batch_data_location= batch_data_location / batch_name\n",
    "    print('Batch found',batch_data_location)\n",
    "else: \n",
    "    print(f'PROBLEM FOUND: the requested batch name {batch_name} does not apear in the folder: {batch_data_location}')\n",
    "\n",
    "\n",
    "PATH_TO_DATA = batch_data_location / 'data'\n",
    "if not PATH_TO_DATA.exists():\n",
    "    print('There is no data folder in the requested location',batch_data_location / 'data')\n",
    "else: \n",
    "    print('Data folder found',batch_data_location / 'data')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A15B4KZ3S04HS8': [999, 1667149704730, 1667223830820, 1667239242566],\n",
       " 'A1LA6CIGBNDOH9': [999, 1667156876722, 1667237966478],\n",
       " 'A22HIX1M4QXZBB': [999, 1666804285762, 1666882028114],\n",
       " 'A248QG4DPULP46': [999, 1666796745860, 1666875548743],\n",
       " 'A2J1DNVMJ56JG1': [999, 1666806879557, 1666887012627],\n",
       " 'A2J57IBR2XIWLS': [999, 1667171400527, 1667244911656, 1667248541474],\n",
       " 'A3MIDLO5S7FU06': [999, 1667148924846, 1667227496622],\n",
       " 'A3U0GQGAPN2DAV': [999, 1667148683750, 1667239544108],\n",
       " 'A5P12YJP805RG': [999, 1667147891427, 1667216156787, 1667226130459],\n",
       " 'ASNNAP90D5R1Z': [999, 1667152406322, 1667216854306, 1667237576573],\n",
       " 'A1JJYY622DGE5L': [0, 1667410475964, 1667477742569],\n",
       " 'A2KDZLWD8RAHDM': [999, 1667410512595],\n",
       " 'AE33JO53WTHZQ': [4, 1667410525427, 1667460407566, 1667492580892],\n",
       " 'A4ANRSA55IW5Q': [5, 1667410579171, 1667460858095],\n",
       " 'A11EXIB1MVBZFJ': [6,\n",
       "  1667410584962,\n",
       "  1667481177705,\n",
       "  1667481243565,\n",
       "  1667486537259],\n",
       " 'AMEBLCWTZKLS2': [8, 1667410598167, 1667492835383],\n",
       " 'A3EBIC3PKUSKCL': [9, 1667410616477],\n",
       " 'A1PN0EFQD8OHSU': [999, 999, 999],\n",
       " 'ASVSPBUO4YRBT': [999,\n",
       "  1667410627238,\n",
       "  1667410745681,\n",
       "  1667410971272,\n",
       "  1667414162527],\n",
       " 'A10AKR84P1WXHL': [999, 999, 999],\n",
       " 'AVZRZOK0F26P6': [12,\n",
       "  1667410735707,\n",
       "  1667460650866,\n",
       "  1667464035856,\n",
       "  1667470051189],\n",
       " 'A3EWBTHYFI4I6Q': [999, 1667410796338, 1667411217538, 1667412334055],\n",
       " 'A1MT4FMXL4WRAF': [999, 999, 999],\n",
       " 'ABGKJYEITBKIL': [999, 999, 999],\n",
       " 'AK4WAT44YKU7J': [14, 1667410895492, 1667499225041],\n",
       " 'A23OK9EV00HCR4': [999, 1667410896026, 1667411400167, 1667411936244],\n",
       " 'A3VHDQR8A9JJ4F': [15, 1667410936684, 1667481841208, 1667489120043],\n",
       " 'AL113DDABUJQ0': [999, 999, 999],\n",
       " 'A1CB9NR3SN4VMY': [999, 999, 999],\n",
       " 'AB8XECKH1JO8P': [18, 1667411003183, 1667477788852],\n",
       " 'A2HY7GQ07YIZTT': [999, 1667411105519],\n",
       " 'A33PJ8605347GY': [999, 1667411126127, 1667411219518],\n",
       " 'A1W0K28IND6NR4': [999, 1667411170189],\n",
       " 'A2U50SMRZT60ZF': [999, 1667411316900],\n",
       " 'A1U0FDPQ953KXX': [23,\n",
       "  1667411372469,\n",
       "  1667460670237,\n",
       "  1667486731278,\n",
       "  1667487481938],\n",
       " 'AZNWNTQ47L88M': [999,\n",
       "  1667411391333,\n",
       "  1667412316025,\n",
       "  1667412683374,\n",
       "  1667412895440],\n",
       " 'A2M183CETUMR96': [26, 1667411416274, 1667508073675],\n",
       " 'A1LCUPRZ0I8S3I': [27, 1667411428866, 1667411954191, 1667491335070],\n",
       " 'A1L5A88C9PPK5L': [999, 1667411482584, 1667411924868],\n",
       " 'A3UZ5V4Y0K3YPV': [29, 1667411545745],\n",
       " 'A2FQLA1NF502GW': [999, 1667411467356, 1667411876434],\n",
       " 'AEHH65WR5E3L6': [999, 1667411673797],\n",
       " 'ATA61WNUAP91U': [33,\n",
       "  1667411683834,\n",
       "  1667460503131,\n",
       "  1667460556038,\n",
       "  1667474685059,\n",
       "  1667485798828,\n",
       "  1667485989768,\n",
       "  1667486779367,\n",
       "  1667487486096],\n",
       " 'A149YZJBFRDWBJ': [34, 1667411770370, 1667464142055],\n",
       " 'A1SL80AWG592HX': [999, 1667411857667],\n",
       " 'A1I1IMZ2ROJY3I': [999, 1667412158260],\n",
       " 'A1B2U0G48Y1U52': [999,\n",
       "  1667412168250,\n",
       "  1667412628125,\n",
       "  1667413623675,\n",
       "  1667413924624,\n",
       "  1667414164762],\n",
       " 'A3NME80IO3UFFO': [999, 1667412504694],\n",
       " 'A1TH9QF8FD0SF5': [999, 1667412423095, 1667412467798, 1667412725256],\n",
       " 'A3RDT5DH21PVAR': [40, 1667412557169, 1667463111081, 1667489384949],\n",
       " 'A1F9KLZGHE9DTA': [41, 1667412665463, 1667477099376, 1667490931872],\n",
       " 'A2PTABUVOUYAH5': [999, 1667413036111],\n",
       " 'ALAEBEEHK525U': [999, 1667413197979, 1667413278101],\n",
       " 'A201VG3B3F1Q40': [999, 1667413385261, 1667413892002],\n",
       " 'A3USIO03UXTDUT': [999, 1667413691795],\n",
       " 'AVP8OEUW3NB4D': [999, 1667413739582],\n",
       " 'A2ASRB2MTHDHPD': [48,\n",
       "  1667413818790,\n",
       "  1667460588952,\n",
       "  1667460634014,\n",
       "  1667463332414,\n",
       "  1667469223330,\n",
       "  1667477780124,\n",
       "  1667491030413],\n",
       " 'A3OU2PDA0ZTT4P': [999, 1667414057681, 1667414109456],\n",
       " 'ATRB1HXZI3J2P': [999, 1667414114770, 1667414870410],\n",
       " 'A1HUQ7QA5QWM5Q': [999, 999, 999],\n",
       " 'A2A66W3JTSP642': [52, 1667414300849, 1667463264844, 1667463345795],\n",
       " 'A98E8M4QLI9RS': [53, 1667414307130, 1667496258234],\n",
       " 'A2F5SKVBQQXFX0': [999, 999, 999],\n",
       " 'A3FJQY40AAYLDF': [51, 1667414420527],\n",
       " 'A12K1ADYMRSWMJ': [999, 1667428873368],\n",
       " 'A31FDAPJJ2EBGA': [55,\n",
       "  1667414651812,\n",
       "  1667474991019,\n",
       "  1667476033621,\n",
       "  1667476361011],\n",
       " 'A1W9HGZ8IKQMTW': [999, 1667414589575],\n",
       " 'A3JJXDML3XNSQP': [57, 1667414639083, 1667480092020, 1667495850160],\n",
       " 'A1OOCYEFLAJD98': [58, 1667414710731, 1667504143232],\n",
       " 'A5AE8MWFQVBX62': [999, 1667414713167],\n",
       " 'A129Y082RKJN6V': [999, 1667414976124, 1667415066714, 1667415232165],\n",
       " 'ASQJWS2HM0ZW9': [999, 1667415007137],\n",
       " 'A5JWBZ2885D1N': [999, 999, 999],\n",
       " 'A14CZ7WXO9TOSX': [999, 999, 999],\n",
       " 'AEOLA4FY5IDHE': [999, 999, 999],\n",
       " 'A2Y8LZS5C81O25': [999, 999, 999],\n",
       " 'AQC0KPAOX4ZPL': [999, 999, 999],\n",
       " 'A3NAONPCTVT6P1': [999, 999, 999],\n",
       " 'A2PF6UAA5SUVD0': [999, 999, 999],\n",
       " 'A319QISFZHTOGY': [1000],\n",
       " 'A100FVY6N5ROG6': [1000],\n",
       " 'A290Z6QAL17PQE': [999, 999, 999],\n",
       " 'A2MQPQ30Z0ETL4': [999, 999, 999],\n",
       " 'A2BUHMLNE3LUU0': [999,\n",
       "  1667425773436,\n",
       "  1667425900929,\n",
       "  1667426336350,\n",
       "  1667427580185],\n",
       " 'AG6UL22QLCKOG': [999, 999, 999],\n",
       " 'A29DB0P3TCTY3I': [999, 999, 999],\n",
       " 'A1Y0ZBE9UBJV2S': [999, 999, 999],\n",
       " 'A3Q228ENXTJ38F': [999, 999, 999],\n",
       " 'A1NQVG69U3TRDK': [999, 999, 999],\n",
       " 'A39IAY6VBVR8FD': [999, 999, 999],\n",
       " 'A3JRY3AL756S3P': [999, 999, 999],\n",
       " 'AP9YNGPNQSX7I': [999, 999, 999],\n",
       " 'A29O6FOYRB10S2': [999, 999, 999],\n",
       " 'A31YK51P992Q4L': [999, 999, 999, 1667452473135],\n",
       " 'AUGML2ZY46M47': [999, 999, 999],\n",
       " 'AQCZJ81IS07OK': [999, 999, 1667451864242],\n",
       " 'A2HFHW1AT6CYCV': [999, 999, 999],\n",
       " 'A2A66Wjgsvjmdcmc': [1, 1667464782624],\n",
       " 'A2BUHMLNE3LUU1': [2, 1667515288683]}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this section loads the shelf dict in the state it is after finishing the testing session for this batch. \n",
    "shelf_dict_after_test_name=batch_data_location / 'shelf after test session closed.txt' #define the name of the relevant shelf for this stage\n",
    "with open(shelf_dict_after_test_name) as f:\n",
    "    data = f.read()\n",
    "shelf_dict = json.loads(data)\n",
    "shelf_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this section reads all the relevant files: \n",
    "if (batch_data_location / 'Batch_encoding_batch_results.csv').exists():\n",
    "    encoding_df=pd.read_csv(batch_data_location / 'Batch_encoding_batch_results.csv')\n",
    "else: \n",
    "    print(f'no \"Batch_encoding_batch_results.csv\" was found in data')\n",
    "\n",
    "if (batch_data_location / 'Batch_testing_batch_results.csv').exists():\n",
    "    testing_df=pd.read_csv(batch_data_location / 'Batch_testing_batch_results.csv')\n",
    "else: \n",
    "    print(f'no \"Batch_testing_batch_results.csv\" was found in data (probably because only the encoding session finished)')\n",
    "if (batch_data_location / 'Batch_workers_after_test.csv').exists():\n",
    "    workers_df=pd.read_csv(batch_data_location / 'Batch_workers_after_test.csv')\n",
    "else:\n",
    "    print('No AMAZON worker list was found: please make sure to upload one and name it correctly')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_largest_consequtive_repetition(responses_array):\n",
    "#add a stop value so the loop will use the logic also if the end of the responses is all repeating: \n",
    "    responses_array=np.append(responses_array,[99])\n",
    "    longest_rep_dict=dict()\n",
    "    last_input=responses_array[0]\n",
    "    consequtive_rep_counter=0\n",
    "    for response in responses_array[1:]: \n",
    "        if response==last_input: #if consequtive rep: \n",
    "            consequtive_rep_counter=consequtive_rep_counter+1 #add to counter\n",
    "        else: #once a new entry is in the vector - store the counter rep information \n",
    "            if last_input in longest_rep_dict.keys(): #if it was allready stored in our dictionary\n",
    "                if longest_rep_dict[last_input]<consequtive_rep_counter: #replace the counter only if it is higher than what stored in dict\n",
    "                    longest_rep_dict[last_input]=consequtive_rep_counter\n",
    "            else: #this entry is not yet in the dictionary: add it \n",
    "                longest_rep_dict[last_input]=consequtive_rep_counter\n",
    "            \n",
    "            consequtive_rep_counter=0\n",
    "            last_input=response\n",
    "    return max(longest_rep_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_worker_results(PATH_TO_BATCH,subject_name,parse_type='encoding'):\n",
    "    cur_sub=pd.read_csv(PATH_TO_BATCH / subject_name)\n",
    "    sub_demographics=cur_sub[['workID','Age','Gender']].iloc[0]\n",
    "\n",
    "    #extract demo related information: \n",
    "\n",
    "    #if participant did not click on the arrow during the demo a 'demo_encoding_response.rt' colmumn wont exists: \n",
    "    #thus we will create one and fill it with nans (so everything will be consistent with other participants)\n",
    "    if not('demo_encoding_response.rt' in cur_sub.columns):\n",
    "        cur_sub['demo_encoding_response.rt']=np.nan\n",
    "    demo_columns=['demo_encoding_loop.thisTrialN','DemoImage','DemoCorrect','demo_encoding_response.rt','demo_encoding_response.keys']\n",
    "\n",
    "    if (parse_type=='encoding'):\n",
    "        sub_demo_information=cur_sub[demo_columns]\n",
    "        empty_inds=sub_demo_information.loc[sub_demo_information.isnull().apply(lambda x: all(x), axis=1)].index\n",
    "        #drop irrelevant columns: \n",
    "        sub_demo_information=sub_demo_information.drop(index=empty_inds)\n",
    "\n",
    "\n",
    "        #extract the demo test columns: \n",
    "        demo_test_columns=['demo_test_response.keys','demo_test_response.corr','demo_test_response.rt','demo_test_loop.thisTrialN','DemoImage1','DemoImage2','DemoCorrectTest']\n",
    "        sub_demo_test_information=cur_sub[demo_test_columns]\n",
    "        empty_inds=sub_demo_test_information.loc[sub_demo_test_information.isnull().apply(lambda x: all(x), axis=1)].index\n",
    "        #drop irrelevant columns: \n",
    "        sub_demo_test_information=sub_demo_test_information.drop(index=empty_inds)\n",
    "\n",
    "        demo_df=pd.concat([sub_demo_information.reset_index(),sub_demo_test_information.reset_index()],axis=1)\n",
    "\n",
    "    #extract real experiment related information: \n",
    "\n",
    "    #if participant did not click on the arrow during the encoding a 'test_encoding_response.rt' column wont exists: \n",
    "    #thus we will create one and fill it with nans (so everything will be consistent with other participants)\n",
    "    if not('test_encoding_response.rt' in cur_sub.columns):\n",
    "        cur_sub['test_encoding_response.rt']=np.nan\n",
    "\n",
    "\n",
    "    if (parse_type=='encoding') | (parse_type=='all'):\n",
    "        encoding_related_columns=['test_encoding_response.keys','test_encoding_response.corr','trials.thisTrialN','target_image','pair','layer','correct','test_encoding_response.rt','key_resp_end.keys']\n",
    "        sub_encoding_information=cur_sub[encoding_related_columns]\n",
    "        #encoding section ends with a key press of the space key: so seperate this phase by finding this space key row\n",
    "        end_of_section_ind=np.where(sub_encoding_information['key_resp_end.keys']=='space')[0][0]\n",
    "        sub_encoding_information=sub_encoding_information.iloc[0:end_of_section_ind]\n",
    "        #remove all the rows that precede the real encoding phase: \n",
    "        empty_inds=sub_encoding_information.loc[sub_encoding_information.isnull().apply(lambda x: all(x), axis=1)].index\n",
    "        sub_encoding_information=sub_encoding_information.drop(index=empty_inds).reset_index()\n",
    "\n",
    "    if (parse_type=='test') | (parse_type=='all'):\n",
    "    #extract real experiment TEST related information: \n",
    "        test_related_columns=['layer','correct','test_test_response.keys','test_test_response.corr','test_test_response.rt','trials_2.thisRepN','trials_2.thisTrialN','trials_2.thisN','trials_2.thisIndex','trials_2.ran','image1','image2']\n",
    "        sub_test_information=cur_sub[test_related_columns].dropna()\n",
    "\n",
    "\n",
    "    subject_dictionary=dict()\n",
    "    subject_dictionary['demographics']=sub_demographics\n",
    "    if (parse_type=='encoding') | (parse_type=='all'):\n",
    "        subject_dictionary['demo_df']=demo_df\n",
    "    if (parse_type=='encoding') | (parse_type=='all'):\n",
    "        subject_dictionary['encoding_df']=sub_encoding_information\n",
    "    if (parse_type=='test') | (parse_type=='all'):\n",
    "        subject_dictionary['test_df']=sub_test_information\n",
    "\n",
    "    return subject_dictionary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current csv files:\n",
      "[WindowsPath('c:/Users/User/Desktop/visualpilot2/Visual-memory-task/data/pilot_24_hours/batch 3/data/ENCODING_A11EXIB1MVBZFJ_2022-11-02_13h36.24.962.csv'), WindowsPath('c:/Users/User/Desktop/visualpilot2/Visual-memory-task/data/pilot_24_hours/batch 3/data/ENCODING_A12K1ADYMRSWMJ_2022-11-02_18h41.13.368.csv'), WindowsPath('c:/Users/User/Desktop/visualpilot2/Visual-memory-task/data/pilot_24_hours/batch 3/data/ENCODING_A149YZJBFRDWBJ_2022-11-02_13h56.10.370.csv'), WindowsPath('c:/Users/User/Desktop/visualpilot2/Visual-memory-task/data/pilot_24_hours/batch 3/data/ENCODING_A1F9KLZGHE9DTA_2022-11-02_14h11.05.463.csv'), WindowsPath('c:/Users/User/Desktop/visualpilot2/Visual-memory-task/data/pilot_24_hours/batch 3/data/ENCODING_A1JJYY622DGE5L_2022-11-02_13h34.35.964.csv'), WindowsPath('c:/Users/User/Desktop/visualpilot2/Visual-memory-task/data/pilot_24_hours/batch 3/data/ENCODING_A1L5A88C9PPK5L_2022-11-02_10h51.22.584.csv'), WindowsPath('c:/Users/User/Desktop/visualpilot2/Visual-memory-task/data/pilot_24_hours/batch 3/data/ENCODING_A1LCUPRZ0I8S3I_2022-11-02_13h50.28.866.csv'), WindowsPath('c:/Users/User/Desktop/visualpilot2/Visual-memory-task/data/pilot_24_hours/batch 3/data/ENCODING_A1OOCYEFLAJD98_2022-11-02_13h45.10.731.csv'), WindowsPath('c:/Users/User/Desktop/visualpilot2/Visual-memory-task/data/pilot_24_hours/batch 3/data/ENCODING_A1SL80AWG592HX_2022-11-02_13h57.37.667.csv'), WindowsPath('c:/Users/User/Desktop/visualpilot2/Visual-memory-task/data/pilot_24_hours/batch 3/data/ENCODING_A1U0FDPQ953KXX_2022-11-02_11h49.32.469.csv'), WindowsPath('c:/Users/User/Desktop/visualpilot2/Visual-memory-task/data/pilot_24_hours/batch 3/data/ENCODING_A2A66W3JTSP642_2022-11-02_14h38.20.849.csv'), WindowsPath('c:/Users/User/Desktop/visualpilot2/Visual-memory-task/data/pilot_24_hours/batch 3/data/ENCODING_A2ASRB2MTHDHPD_2022-11-02_14h30.18.790.csv'), WindowsPath('c:/Users/User/Desktop/visualpilot2/Visual-memory-task/data/pilot_24_hours/batch 3/data/ENCODING_A2FQLA1NF502GW_2022-11-02_11h51.07.356.csv'), WindowsPath('c:/Users/User/Desktop/visualpilot2/Visual-memory-task/data/pilot_24_hours/batch 3/data/ENCODING_A2HY7GQ07YIZTT_2022-11-02_13h45.05.519.csv'), WindowsPath('c:/Users/User/Desktop/visualpilot2/Visual-memory-task/data/pilot_24_hours/batch 3/data/ENCODING_A2M183CETUMR96_2022-11-02_12h50.16.274.csv'), WindowsPath('c:/Users/User/Desktop/visualpilot2/Visual-memory-task/data/pilot_24_hours/batch 3/data/ENCODING_A31FDAPJJ2EBGA_2022-11-02_13h44.11.812.csv'), WindowsPath('c:/Users/User/Desktop/visualpilot2/Visual-memory-task/data/pilot_24_hours/batch 3/data/ENCODING_A3EBIC3PKUSKCL_2022-11-02_12h36.56.477.csv'), WindowsPath('c:/Users/User/Desktop/visualpilot2/Visual-memory-task/data/pilot_24_hours/batch 3/data/ENCODING_A3FJQY40AAYLDF_2022-11-02_11h40.20.527.csv'), WindowsPath('c:/Users/User/Desktop/visualpilot2/Visual-memory-task/data/pilot_24_hours/batch 3/data/ENCODING_A3JJXDML3XNSQP_2022-11-02_15h43.59.083.csv'), WindowsPath('c:/Users/User/Desktop/visualpilot2/Visual-memory-task/data/pilot_24_hours/batch 3/data/ENCODING_A3RDT5DH21PVAR_2022-11-02_14h09.17.169.csv'), WindowsPath('c:/Users/User/Desktop/visualpilot2/Visual-memory-task/data/pilot_24_hours/batch 3/data/ENCODING_A3USIO03UXTDUT_2022-11-02_14h28.11.795.csv'), WindowsPath('c:/Users/User/Desktop/visualpilot2/Visual-memory-task/data/pilot_24_hours/batch 3/data/ENCODING_A3UZ5V4Y0K3YPV_2022-11-02_13h52.25.745.csv'), WindowsPath('c:/Users/User/Desktop/visualpilot2/Visual-memory-task/data/pilot_24_hours/batch 3/data/ENCODING_A3VHDQR8A9JJ4F_2022-11-02_13h42.16.684.csv'), WindowsPath('c:/Users/User/Desktop/visualpilot2/Visual-memory-task/data/pilot_24_hours/batch 3/data/ENCODING_A4ANRSA55IW5Q_2022-11-02_13h36.19.171.csv'), WindowsPath('c:/Users/User/Desktop/visualpilot2/Visual-memory-task/data/pilot_24_hours/batch 3/data/ENCODING_A5AE8MWFQVBX62_2022-11-02_14h45.13.167.csv'), WindowsPath('c:/Users/User/Desktop/visualpilot2/Visual-memory-task/data/pilot_24_hours/batch 3/data/ENCODING_A98E8M4QLI9RS_2022-11-02_14h38.27.130.csv'), WindowsPath('c:/Users/User/Desktop/visualpilot2/Visual-memory-task/data/pilot_24_hours/batch 3/data/ENCODING_AB8XECKH1JO8P_2022-11-02_10h43.23.183.csv'), WindowsPath('c:/Users/User/Desktop/visualpilot2/Visual-memory-task/data/pilot_24_hours/batch 3/data/ENCODING_AE33JO53WTHZQ_2022-11-02_13h35.25.427.csv'), WindowsPath('c:/Users/User/Desktop/visualpilot2/Visual-memory-task/data/pilot_24_hours/batch 3/data/ENCODING_AK4WAT44YKU7J_2022-11-02_12h41.35.492.csv'), WindowsPath('c:/Users/User/Desktop/visualpilot2/Visual-memory-task/data/pilot_24_hours/batch 3/data/ENCODING_AMEBLCWTZKLS2_2022-11-02_13h36.38.167.csv'), WindowsPath('c:/Users/User/Desktop/visualpilot2/Visual-memory-task/data/pilot_24_hours/batch 3/data/ENCODING_ATA61WNUAP91U_2022-11-02_13h54.43.834.csv'), WindowsPath('c:/Users/User/Desktop/visualpilot2/Visual-memory-task/data/pilot_24_hours/batch 3/data/ENCODING_AVP8OEUW3NB4D_2022-11-02_23h58.59.582.csv'), WindowsPath('c:/Users/User/Desktop/visualpilot2/Visual-memory-task/data/pilot_24_hours/batch 3/data/ENCODING_AVZRZOK0F26P6_2022-11-02_13h38.55.707.csv')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#get all results with Encoding information - extract the arrow attention check accuracy and RT (RT is currently not usd as a criterion)\n",
    "\n",
    "#this section extract the list of participants from the downloaded results files (and not via the workers or session list csvs) \n",
    "# - it will create the qualification_df (a table with information on the worker ids and encoding behavior of all participants that we have files for)\n",
    "all_filenames=[file for file in PATH_TO_DATA.iterdir() if 'csv' in file.name and 'ENCODING' in file.name]\n",
    "print(f'current csv files:\\n{all_filenames}')\n",
    "\n",
    "qualification_for_test_df=pd.DataFrame(columns=['workerID','arrow_acc','mean_arrow_RT'])\n",
    "for subject_csv in all_filenames:\n",
    "    subject_dict=process_worker_results(PATH_TO_DATA,path.Path(subject_csv))\n",
    "    cur_sub_encoding=subject_dict['encoding_df']\n",
    "\n",
    "    sname=subject_csv.name.split('_')[1] #change according to actuall format. \n",
    "\n",
    "    #get only attention check related info: \n",
    "    cur_sub_encoding=cur_sub_encoding[['test_encoding_response.keys','correct','test_encoding_response.rt']].copy().dropna(how = 'all')\n",
    "    if len(cur_sub_encoding)==0: #empty - the participant didnt respond on the arrow at all\n",
    "        arrow_acc=0\n",
    "        RT=nan\n",
    "    else: \n",
    "        RT=cur_sub_encoding['test_encoding_response.rt'].mean()\n",
    "        arrow_acc=(cur_sub_encoding['correct']==cur_sub_encoding['test_encoding_response.keys']).mean()\n",
    "    sub_df=pd.DataFrame({'workerID':sname,'arrow_acc':arrow_acc,'mean_arrow_RT':RT},index=[sname])\n",
    "    qualification_for_test_df=pd.concat([qualification_for_test_df,sub_df],axis=0)\n",
    "\n",
    "#the following part update the qualification_df with information on wether the participant id exists in the amazon workers list: \n",
    "\n",
    "#change participants qualifications if they exists in the workers list based on thier encoding arrow accuracy\n",
    "qualification_for_test_df['in_encoding_workers_list']=nan\n",
    "\n",
    "for curr_worker_ID in qualification_for_test_df.index:\n",
    "    if curr_worker_ID in encoding_df['WorkerId'].values:\n",
    "        qualification_for_test_df.loc[curr_worker_ID,'in_encoding_workers_list']=int(1)\n",
    "    else:\n",
    "        qualification_for_test_df.loc[curr_worker_ID,'in_encoding_workers_list']=int(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subjects_demo_df=pd.DataFrame()\n",
    "all_subjects_encoding_df=pd.DataFrame()\n",
    "all_subjects_test_df=pd.DataFrame()\n",
    "all_subjects_biographics_df=pd.DataFrame()\n",
    "all_filenames=[file.name for file in PATH_TO_DATA.iterdir() if 'csv' in file.name and 'TEST' in file.name]\n",
    "\n",
    "for subject_test_filename in all_filenames:\n",
    "    subject_name=subject_test_filename.split('_')[1]\n",
    "    subject_encoding_filename=[file.name for file in PATH_TO_DATA.iterdir() if 'csv' in file.name and 'ENCODING' in file.name and subject_name in file.name][0]\n",
    "    curr_subject_dictionary=process_worker_results(PATH_TO_DATA,subject_encoding_filename,parse_type='encoding')\n",
    "    curr_demo_df=curr_subject_dictionary['demo_df']\n",
    "    curr_demo_df['subject']=subject_name\n",
    "    curr_encoding_df=curr_subject_dictionary['encoding_df']\n",
    "    curr_encoding_df['subject']=subject_name\n",
    "    curr_demographics_df=curr_subject_dictionary['demographics']\n",
    "    curr_demographics_df['subject']=subject_name\n",
    "\n",
    "    #get the name of this participant encoding: \n",
    "\n",
    "    curr_subject_dictionary=process_worker_results(PATH_TO_DATA,subject_test_filename,parse_type='test')\n",
    "    curr_test_df=curr_subject_dictionary['test_df']\n",
    "    curr_test_df['subject']=subject_name\n",
    "\n",
    "\n",
    "\n",
    "    all_subjects_demo_df=pd.concat([all_subjects_demo_df,curr_demo_df],axis=0,ignore_index=True)\n",
    "    all_subjects_encoding_df=pd.concat([all_subjects_encoding_df,curr_encoding_df],axis=0,ignore_index=True)\n",
    "    all_subjects_test_df=pd.concat([all_subjects_test_df,curr_test_df],axis=0,ignore_index=True)\n",
    "    all_subjects_biographics_df=pd.concat([all_subjects_biographics_df,pd.DataFrame(curr_demographics_df).T],axis=0,ignore_index=True)\n",
    "\n",
    "\n",
    "all_subjects_demo_df.to_csv(PATH_TO_DATA.parent / 'all_subjects_demo_df.csv')\n",
    "all_subjects_encoding_df.to_csv(PATH_TO_DATA.parent / 'all_subjects_encoding_df.csv')\n",
    "all_subjects_test_df.to_csv(PATH_TO_DATA.parent / 'all_subjects_test_df.csv')\n",
    "all_subjects_biographics_df.to_csv(PATH_TO_DATA.parent / 'all_subjects_biographics_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender is still inconsistent with more than 2 unique values: ['Men' 'female' 'male']\n",
      "Mean age: 40.13, range: [23 - 67], 0.33% female\n"
     ]
    }
   ],
   "source": [
    "from unicodedata import category\n",
    "\n",
    "# if there are any empty values - fill with mean of subjects age \n",
    "mean_value = all_subjects_biographics_df['Age'].mean()\n",
    "all_subjects_biographics_df['Age'].fillna(value=mean_value, inplace=True)\n",
    "all_subjects_biographics_df['Age'] = all_subjects_biographics_df['Age'].astype(np.int64)\n",
    "\n",
    "all_subjects_biographics_df['Age']=all_subjects_biographics_df['Age'].astype(int)\n",
    "all_subjects_biographics_df['Gender'].replace({'woman':'female','FEMLAE':'female','Male':'male','MALE':'male','FEMALE':'female','Female':'female','ale':'male'},inplace=True)\n",
    "if len(np.unique(all_subjects_biographics_df['Gender'].values))<=2:\n",
    "    print('transformed the gender column to be consistent having two possible values:',np.unique(all_subjects_biographics_df['Gender'].values))\n",
    "else: \n",
    "    print('gender is still inconsistent with more than 2 unique values:',np.unique(all_subjects_biographics_df['Gender'].values))\n",
    "all_subjects_biographics_df['Gender']=all_subjects_biographics_df['Gender'].astype(\"category\")\n",
    "\n",
    "mean_age,min_age,max_age=all_subjects_biographics_df['Age'].mean(),all_subjects_biographics_df['Age'].min(),all_subjects_biographics_df['Age'].max()\n",
    "female_prop=all_subjects_biographics_df.loc[all_subjects_biographics_df['Gender']=='female','Gender'].count()/all_subjects_biographics_df['Gender'].count()\n",
    "\n",
    "print(f'Mean age: {mean_age:.2f}, range: [{min_age} - {max_age}], {female_prop:.2f}% female')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# this part plots the seperate dataframes: \n",
    "### demo phase (encoding and test in the same dataframe)\n",
    "### encoding experiment phase\n",
    "### test experiment phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>demo_encoding_loop.thisTrialN</th>\n",
       "      <th>DemoImage</th>\n",
       "      <th>DemoCorrect</th>\n",
       "      <th>demo_encoding_response.rt</th>\n",
       "      <th>demo_encoding_response.keys</th>\n",
       "      <th>index</th>\n",
       "      <th>demo_test_response.keys</th>\n",
       "      <th>demo_test_response.corr</th>\n",
       "      <th>demo_test_response.rt</th>\n",
       "      <th>demo_test_loop.thisTrialN</th>\n",
       "      <th>DemoImage1</th>\n",
       "      <th>DemoImage2</th>\n",
       "      <th>DemoCorrectTest</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>flower1.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>left</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>flower1.jpg</td>\n",
       "      <td>flower1_pair.jpg</td>\n",
       "      <td>left</td>\n",
       "      <td>A11EXIB1MVBZFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>flower2.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>right</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.897</td>\n",
       "      <td>1.0</td>\n",
       "      <td>flower2_pair.jpg</td>\n",
       "      <td>flower2.jpg</td>\n",
       "      <td>right</td>\n",
       "      <td>A11EXIB1MVBZFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>left.jpg</td>\n",
       "      <td>left</td>\n",
       "      <td>1.156</td>\n",
       "      <td>left</td>\n",
       "      <td>14.0</td>\n",
       "      <td>left</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.285</td>\n",
       "      <td>2.0</td>\n",
       "      <td>flower3.jpg</td>\n",
       "      <td>flower3_pair.jpg</td>\n",
       "      <td>left</td>\n",
       "      <td>A11EXIB1MVBZFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>flower3.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>left</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.122</td>\n",
       "      <td>3.0</td>\n",
       "      <td>flower4.jpg</td>\n",
       "      <td>flower4_pair.jpg</td>\n",
       "      <td>left</td>\n",
       "      <td>A11EXIB1MVBZFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>flower4.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>right</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.966</td>\n",
       "      <td>4.0</td>\n",
       "      <td>flower5_pair.jpg</td>\n",
       "      <td>flower5.jpg</td>\n",
       "      <td>right</td>\n",
       "      <td>A11EXIB1MVBZFJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  demo_encoding_loop.thisTrialN    DemoImage DemoCorrect  \\\n",
       "0      4                            0.0  flower1.jpg         NaN   \n",
       "1      5                            1.0  flower2.jpg         NaN   \n",
       "2      6                            2.0     left.jpg        left   \n",
       "3      7                            3.0  flower3.jpg         NaN   \n",
       "4      8                            4.0  flower4.jpg         NaN   \n",
       "\n",
       "   demo_encoding_response.rt demo_encoding_response.keys  index  \\\n",
       "0                        NaN                         NaN   12.0   \n",
       "1                        NaN                         NaN   13.0   \n",
       "2                      1.156                        left   14.0   \n",
       "3                        NaN                         NaN   15.0   \n",
       "4                        NaN                         NaN   16.0   \n",
       "\n",
       "  demo_test_response.keys  demo_test_response.corr  demo_test_response.rt  \\\n",
       "0                    left                      1.0                 28.483   \n",
       "1                   right                      1.0                 15.897   \n",
       "2                    left                      1.0                  2.285   \n",
       "3                    left                      1.0                  2.122   \n",
       "4                   right                      1.0                  9.966   \n",
       "\n",
       "   demo_test_loop.thisTrialN        DemoImage1        DemoImage2  \\\n",
       "0                        0.0       flower1.jpg  flower1_pair.jpg   \n",
       "1                        1.0  flower2_pair.jpg       flower2.jpg   \n",
       "2                        2.0       flower3.jpg  flower3_pair.jpg   \n",
       "3                        3.0       flower4.jpg  flower4_pair.jpg   \n",
       "4                        4.0  flower5_pair.jpg       flower5.jpg   \n",
       "\n",
       "  DemoCorrectTest         subject  \n",
       "0            left  A11EXIB1MVBZFJ  \n",
       "1           right  A11EXIB1MVBZFJ  \n",
       "2            left  A11EXIB1MVBZFJ  \n",
       "3            left  A11EXIB1MVBZFJ  \n",
       "4           right  A11EXIB1MVBZFJ  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_subjects_demo_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>test_encoding_response.keys</th>\n",
       "      <th>test_encoding_response.corr</th>\n",
       "      <th>trials.thisTrialN</th>\n",
       "      <th>target_image</th>\n",
       "      <th>pair</th>\n",
       "      <th>layer</th>\n",
       "      <th>correct</th>\n",
       "      <th>test_encoding_response.rt</th>\n",
       "      <th>key_resp_end.keys</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2592379964-131054.jpg</td>\n",
       "      <td>2592380272-354673.jpg</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A11EXIB1MVBZFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2898635427-367120.jpg</td>\n",
       "      <td>2898621427-366486.jpg</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A11EXIB1MVBZFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2458347385-199723.jpg</td>\n",
       "      <td>2458347252-348911.jpg</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A11EXIB1MVBZFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2512875899-126682.jpg</td>\n",
       "      <td>2592380177-354628.jpg</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A11EXIB1MVBZFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2238481928-19949.jpg</td>\n",
       "      <td>2883264367-365620.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A11EXIB1MVBZFJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index test_encoding_response.keys  test_encoding_response.corr  \\\n",
       "0     20                         NaN                          1.0   \n",
       "1     21                         NaN                          1.0   \n",
       "2     22                         NaN                          1.0   \n",
       "3     23                         NaN                          1.0   \n",
       "4     24                         NaN                          1.0   \n",
       "\n",
       "   trials.thisTrialN           target_image                   pair  layer  \\\n",
       "0                0.0  2592379964-131054.jpg  2592380272-354673.jpg    3.0   \n",
       "1                1.0  2898635427-367120.jpg  2898621427-366486.jpg    3.0   \n",
       "2                2.0  2458347385-199723.jpg  2458347252-348911.jpg    3.0   \n",
       "3                3.0  2512875899-126682.jpg  2592380177-354628.jpg    2.0   \n",
       "4                4.0   2238481928-19949.jpg  2883264367-365620.jpg    1.0   \n",
       "\n",
       "  correct  test_encoding_response.rt key_resp_end.keys         subject  \n",
       "0     NaN                        NaN               NaN  A11EXIB1MVBZFJ  \n",
       "1     NaN                        NaN               NaN  A11EXIB1MVBZFJ  \n",
       "2     NaN                        NaN               NaN  A11EXIB1MVBZFJ  \n",
       "3     NaN                        NaN               NaN  A11EXIB1MVBZFJ  \n",
       "4     NaN                        NaN               NaN  A11EXIB1MVBZFJ  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_subjects_encoding_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer</th>\n",
       "      <th>correct</th>\n",
       "      <th>test_test_response.keys</th>\n",
       "      <th>test_test_response.corr</th>\n",
       "      <th>test_test_response.rt</th>\n",
       "      <th>trials_2.thisRepN</th>\n",
       "      <th>trials_2.thisTrialN</th>\n",
       "      <th>trials_2.thisN</th>\n",
       "      <th>trials_2.thisIndex</th>\n",
       "      <th>trials_2.ran</th>\n",
       "      <th>image1</th>\n",
       "      <th>image2</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.0</td>\n",
       "      <td>316.708</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2238499057-320266.jpg</td>\n",
       "      <td>2238428357-313623.jpg</td>\n",
       "      <td>A11EXIB1MVBZFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.956</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2901941438-69835.jpg</td>\n",
       "      <td>2460547508-51571.jpg</td>\n",
       "      <td>A11EXIB1MVBZFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2238560245-182099.jpg</td>\n",
       "      <td>2238480980-168129.jpg</td>\n",
       "      <td>A11EXIB1MVBZFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.610</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2864901420-212147.jpg</td>\n",
       "      <td>2864907432-362042.jpg</td>\n",
       "      <td>A11EXIB1MVBZFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.676</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2446759803-49250.jpg</td>\n",
       "      <td>2898635428-69104.jpg</td>\n",
       "      <td>A11EXIB1MVBZFJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   layer correct test_test_response.keys  test_test_response.corr  \\\n",
       "0    1.0   right                   right                      1.0   \n",
       "1    3.0   right                    left                      0.0   \n",
       "2    3.0    left                   right                      0.0   \n",
       "3    1.0   right                   right                      1.0   \n",
       "4    1.0   right                   right                      1.0   \n",
       "\n",
       "   test_test_response.rt  trials_2.thisRepN  trials_2.thisTrialN  \\\n",
       "0                316.708                0.0                  0.0   \n",
       "1                  5.956                0.0                  1.0   \n",
       "2                  3.076                0.0                  2.0   \n",
       "3                  1.610                0.0                  3.0   \n",
       "4                  1.676                0.0                  4.0   \n",
       "\n",
       "   trials_2.thisN  trials_2.thisIndex  trials_2.ran                 image1  \\\n",
       "0             0.0                 0.0           1.0  2238499057-320266.jpg   \n",
       "1             1.0                 1.0           1.0   2901941438-69835.jpg   \n",
       "2             2.0                 2.0           1.0  2238560245-182099.jpg   \n",
       "3             3.0                 3.0           1.0  2864901420-212147.jpg   \n",
       "4             4.0                 4.0           1.0   2446759803-49250.jpg   \n",
       "\n",
       "                  image2         subject  \n",
       "0  2238428357-313623.jpg  A11EXIB1MVBZFJ  \n",
       "1   2460547508-51571.jpg  A11EXIB1MVBZFJ  \n",
       "2  2238480980-168129.jpg  A11EXIB1MVBZFJ  \n",
       "3  2864907432-362042.jpg  A11EXIB1MVBZFJ  \n",
       "4   2898635428-69104.jpg  A11EXIB1MVBZFJ  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_subjects_test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demo_arrow_rt</th>\n",
       "      <th>demo_arrow_correct</th>\n",
       "      <th>demo_demo_accuracy</th>\n",
       "      <th>demo_RT_overall_mean</th>\n",
       "      <th>demo_RT_incorrect_mean</th>\n",
       "      <th>demo_RT_correct_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A11EXIB1MVBZFJ</th>\n",
       "      <td>1.1560</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.790667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.790667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1F9KLZGHE9DTA</th>\n",
       "      <td>0.5979</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.385950</td>\n",
       "      <td>1.740400</td>\n",
       "      <td>1.315060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1LCUPRZ0I8S3I</th>\n",
       "      <td>0.9871</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.185933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.185933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1OOCYEFLAJD98</th>\n",
       "      <td>0.5116</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.427583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.427583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1U0FDPQ953KXX</th>\n",
       "      <td>1.1286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>5.252667</td>\n",
       "      <td>3.311800</td>\n",
       "      <td>5.640840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2ASRB2MTHDHPD</th>\n",
       "      <td>1.2799</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.293650</td>\n",
       "      <td>4.709733</td>\n",
       "      <td>5.877567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2M183CETUMR96</th>\n",
       "      <td>0.5185</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>5.864933</td>\n",
       "      <td>3.148550</td>\n",
       "      <td>11.297700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3JJXDML3XNSQP</th>\n",
       "      <td>1.8620</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>5.357000</td>\n",
       "      <td>15.925000</td>\n",
       "      <td>3.243400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3RDT5DH21PVAR</th>\n",
       "      <td>2.1221</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.208033</td>\n",
       "      <td>1.722100</td>\n",
       "      <td>2.451000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3VHDQR8A9JJ4F</th>\n",
       "      <td>0.6487</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.888650</td>\n",
       "      <td>1.807700</td>\n",
       "      <td>1.904840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A98E8M4QLI9RS</th>\n",
       "      <td>0.4490</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.305167</td>\n",
       "      <td>1.206000</td>\n",
       "      <td>1.354750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AE33JO53WTHZQ</th>\n",
       "      <td>1.3502</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>4.566183</td>\n",
       "      <td>4.398000</td>\n",
       "      <td>4.650275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK4WAT44YKU7J</th>\n",
       "      <td>0.6394</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.239683</td>\n",
       "      <td>2.574500</td>\n",
       "      <td>2.072275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMEBLCWTZKLS2</th>\n",
       "      <td>0.9730</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.663333</td>\n",
       "      <td>1.395000</td>\n",
       "      <td>1.717000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATA61WNUAP91U</th>\n",
       "      <td>1.3853</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>2.389683</td>\n",
       "      <td>2.182800</td>\n",
       "      <td>2.431060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                demo_arrow_rt  demo_arrow_correct  demo_demo_accuracy  \\\n",
       "A11EXIB1MVBZFJ         1.1560                 1.0            1.000000   \n",
       "A1F9KLZGHE9DTA         0.5979                 1.0            0.833333   \n",
       "A1LCUPRZ0I8S3I         0.9871                 1.0            1.000000   \n",
       "A1OOCYEFLAJD98         0.5116                 1.0            1.000000   \n",
       "A1U0FDPQ953KXX         1.1286                 1.0            0.833333   \n",
       "A2ASRB2MTHDHPD         1.2799                 1.0            0.500000   \n",
       "A2M183CETUMR96         0.5185                 1.0            0.333333   \n",
       "A3JJXDML3XNSQP         1.8620                 1.0            0.833333   \n",
       "A3RDT5DH21PVAR         2.1221                 1.0            0.666667   \n",
       "A3VHDQR8A9JJ4F         0.6487                 1.0            0.833333   \n",
       "A98E8M4QLI9RS          0.4490                 1.0            0.666667   \n",
       "AE33JO53WTHZQ          1.3502                 1.0            0.666667   \n",
       "AK4WAT44YKU7J          0.6394                 1.0            0.666667   \n",
       "AMEBLCWTZKLS2          0.9730                 1.0            0.833333   \n",
       "ATA61WNUAP91U          1.3853                 1.0            0.833333   \n",
       "\n",
       "                demo_RT_overall_mean  demo_RT_incorrect_mean  \\\n",
       "A11EXIB1MVBZFJ             15.790667                     NaN   \n",
       "A1F9KLZGHE9DTA              1.385950                1.740400   \n",
       "A1LCUPRZ0I8S3I              2.185933                     NaN   \n",
       "A1OOCYEFLAJD98              2.427583                     NaN   \n",
       "A1U0FDPQ953KXX              5.252667                3.311800   \n",
       "A2ASRB2MTHDHPD              5.293650                4.709733   \n",
       "A2M183CETUMR96              5.864933                3.148550   \n",
       "A3JJXDML3XNSQP              5.357000               15.925000   \n",
       "A3RDT5DH21PVAR              2.208033                1.722100   \n",
       "A3VHDQR8A9JJ4F              1.888650                1.807700   \n",
       "A98E8M4QLI9RS               1.305167                1.206000   \n",
       "AE33JO53WTHZQ               4.566183                4.398000   \n",
       "AK4WAT44YKU7J               2.239683                2.574500   \n",
       "AMEBLCWTZKLS2               1.663333                1.395000   \n",
       "ATA61WNUAP91U               2.389683                2.182800   \n",
       "\n",
       "                demo_RT_correct_mean  \n",
       "A11EXIB1MVBZFJ             15.790667  \n",
       "A1F9KLZGHE9DTA              1.315060  \n",
       "A1LCUPRZ0I8S3I              2.185933  \n",
       "A1OOCYEFLAJD98              2.427583  \n",
       "A1U0FDPQ953KXX              5.640840  \n",
       "A2ASRB2MTHDHPD              5.877567  \n",
       "A2M183CETUMR96             11.297700  \n",
       "A3JJXDML3XNSQP              3.243400  \n",
       "A3RDT5DH21PVAR              2.451000  \n",
       "A3VHDQR8A9JJ4F              1.904840  \n",
       "A98E8M4QLI9RS               1.354750  \n",
       "AE33JO53WTHZQ               4.650275  \n",
       "AK4WAT44YKU7J               2.072275  \n",
       "AMEBLCWTZKLS2               1.717000  \n",
       "ATA61WNUAP91U               2.431060  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this section extract information from the demo phase: it creates a df (all_subjects_summary_demo_info) containingsingle row per participants with metrics from the demo phase (average accuracy, RTs and so on (this can be used to screen participatns for further analysis)):\n",
    "all_subjects_summary_demo_info=pd.DataFrame(index=list(all_subjects_demo_df['subject'].unique()))\n",
    "\n",
    "for cur_subject in all_subjects_demo_df['subject'].unique():\n",
    "    cur_sub_demo_encoding=all_subjects_demo_df.loc[all_subjects_demo_df['subject']==cur_subject]\n",
    "    \n",
    "    #get only attention check related info: \n",
    "    curr_subjects_summary_demo_info=cur_sub_demo_encoding[['demo_encoding_response.keys','DemoCorrect','demo_encoding_response.rt']].copy().dropna()\n",
    "    if len(curr_subjects_summary_demo_info)==0: #empty - the participant didnt respond on the arrow at all: \n",
    "       all_subjects_summary_demo_info.loc[cur_subject,'arrow_correct']=0 \n",
    "       all_subjects_summary_demo_info.loc[cur_subject,'arrow_rt']=np.nan\n",
    "    else: \n",
    "        all_subjects_summary_demo_info.loc[cur_subject,'arrow_rt']=curr_subjects_summary_demo_info['demo_encoding_response.rt'].values\n",
    "        if all(curr_subjects_summary_demo_info['DemoCorrect']==curr_subjects_summary_demo_info['demo_encoding_response.keys']):\n",
    "            all_subjects_summary_demo_info.loc[cur_subject,'arrow_correct']=1\n",
    "        else:\n",
    "            all_subjects_summary_demo_info.loc[cur_subject,'arrow_correct']=0\n",
    "\n",
    "\n",
    "    #get the correctness of the demo testing phase: \n",
    "    cur_sub_demo_test_performence=cur_sub_demo_encoding[['DemoCorrectTest','demo_test_response.keys','demo_test_response.rt']].copy().dropna()\n",
    "    test_match_df=pd.DataFrame(columns=['arrow_correct'],data=cur_sub_demo_test_performence['DemoCorrectTest']==cur_sub_demo_test_performence['demo_test_response.keys'])\n",
    "    test_match_df['demo_test_response.rt']=cur_sub_demo_test_performence['demo_test_response.rt']\n",
    "    accuracy=test_match_df['arrow_correct'].mean()\n",
    "    mean_rt=test_match_df['demo_test_response.rt'].mean()\n",
    "    correct_and_incorrect_rts=test_match_df.groupby('arrow_correct').aggregate({'demo_test_response.rt':'mean'})\n",
    "    #update the summary info row: \n",
    "    all_subjects_summary_demo_info.loc[cur_subject,'demo_accuracy']=accuracy\n",
    "    all_subjects_summary_demo_info.loc[cur_subject,'RT_overall_mean']=mean_rt\n",
    "    all_subjects_summary_demo_info.loc[cur_subject,['RT_incorrect_mean','RT_correct_mean']]=np.nan\n",
    "\n",
    "    if False in correct_and_incorrect_rts.index:\n",
    "        all_subjects_summary_demo_info.loc[cur_subject,'RT_incorrect_mean']=correct_and_incorrect_rts.loc[False].values[0]\n",
    "    if True in correct_and_incorrect_rts.index:\n",
    "        all_subjects_summary_demo_info.loc[cur_subject,'RT_correct_mean']=correct_and_incorrect_rts.loc[True].values[0]\n",
    "\n",
    "\n",
    "#add a prefix to column names: \n",
    "all_subjects_summary_demo_info.columns=['demo_'+col for col in all_subjects_summary_demo_info.columns]\n",
    "all_subjects_summary_demo_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoding_arrow_mean_rt</th>\n",
       "      <th>encoding_arrow_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A11EXIB1MVBZFJ</th>\n",
       "      <td>1.13860</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1F9KLZGHE9DTA</th>\n",
       "      <td>0.59792</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1LCUPRZ0I8S3I</th>\n",
       "      <td>1.37952</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1OOCYEFLAJD98</th>\n",
       "      <td>0.67562</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1U0FDPQ953KXX</th>\n",
       "      <td>1.30840</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2ASRB2MTHDHPD</th>\n",
       "      <td>1.63130</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2M183CETUMR96</th>\n",
       "      <td>0.48240</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3JJXDML3XNSQP</th>\n",
       "      <td>1.37120</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3RDT5DH21PVAR</th>\n",
       "      <td>1.14476</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3VHDQR8A9JJ4F</th>\n",
       "      <td>0.62064</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A98E8M4QLI9RS</th>\n",
       "      <td>0.59220</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AE33JO53WTHZQ</th>\n",
       "      <td>1.10420</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK4WAT44YKU7J</th>\n",
       "      <td>0.52266</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMEBLCWTZKLS2</th>\n",
       "      <td>1.03720</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATA61WNUAP91U</th>\n",
       "      <td>1.27288</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                encoding_arrow_mean_rt  encoding_arrow_accuracy\n",
       "A11EXIB1MVBZFJ                 1.13860                      1.0\n",
       "A1F9KLZGHE9DTA                 0.59792                      1.0\n",
       "A1LCUPRZ0I8S3I                 1.37952                      1.0\n",
       "A1OOCYEFLAJD98                 0.67562                      1.0\n",
       "A1U0FDPQ953KXX                 1.30840                      1.0\n",
       "A2ASRB2MTHDHPD                 1.63130                      1.0\n",
       "A2M183CETUMR96                 0.48240                      1.0\n",
       "A3JJXDML3XNSQP                 1.37120                      1.0\n",
       "A3RDT5DH21PVAR                 1.14476                      0.8\n",
       "A3VHDQR8A9JJ4F                 0.62064                      1.0\n",
       "A98E8M4QLI9RS                  0.59220                      1.0\n",
       "AE33JO53WTHZQ                  1.10420                      0.6\n",
       "AK4WAT44YKU7J                  0.52266                      1.0\n",
       "AMEBLCWTZKLS2                  1.03720                      1.0\n",
       "ATA61WNUAP91U                  1.27288                      1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this part extract summary information from the experiment encoding phase: attention check accuracy and timings: \n",
    "all_subjects_summary_encoding_info=pd.DataFrame(index=list(all_subjects_encoding_df['subject'].unique()))\n",
    "\n",
    "for cur_subject in all_subjects_encoding_df['subject'].unique():\n",
    "    cur_sub_encoding=all_subjects_encoding_df.loc[all_subjects_encoding_df['subject']==cur_subject]\n",
    "    \n",
    "    #get only attention check related info: \n",
    "    cur_sub_encoding=cur_sub_encoding[['test_encoding_response.keys','correct','test_encoding_response.rt']].copy().dropna(how = 'all')\n",
    "    if len(cur_sub_encoding)==0: #empty - the participant didnt respond on the arrow at all: \n",
    "       all_subjects_summary_encoding_info.loc[cur_subject,'arrow_accuracy']=0 \n",
    "       all_subjects_summary_encoding_info.loc[cur_subject,'arrow_mean_rt']=np.nan\n",
    "    else: \n",
    "        all_subjects_summary_encoding_info.loc[cur_subject,'arrow_mean_rt']=cur_sub_encoding['test_encoding_response.rt'].mean()\n",
    "        arrow_accuracy=(cur_sub_encoding['correct']==cur_sub_encoding['test_encoding_response.keys']).mean()\n",
    "        all_subjects_summary_encoding_info.loc[cur_subject,'arrow_accuracy']=arrow_accuracy\n",
    "\n",
    "\n",
    "\n",
    "#add a prefix to column names: \n",
    "all_subjects_summary_encoding_info.columns=['encoding_'+col for col in all_subjects_summary_encoding_info.columns]        \n",
    "all_subjects_summary_encoding_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>testing_Test_overall_accuracy</th>\n",
       "      <th>testing_RT_overall_mean</th>\n",
       "      <th>testing_RT_incorrect_mean</th>\n",
       "      <th>testing_RT_correct_mean</th>\n",
       "      <th>testing_layer_1_rt</th>\n",
       "      <th>testing_layer_1_accuracy</th>\n",
       "      <th>testing_layer_2_rt</th>\n",
       "      <th>testing_layer_2_accuracy</th>\n",
       "      <th>testing_layer_3_rt</th>\n",
       "      <th>testing_layer_3_accuracy</th>\n",
       "      <th>testing_longest_response_strike</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A11EXIB1MVBZFJ</th>\n",
       "      <td>0.516667</td>\n",
       "      <td>2.094241</td>\n",
       "      <td>3.899862</td>\n",
       "      <td>12.155968</td>\n",
       "      <td>2.203368</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.671950</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.429632</td>\n",
       "      <td>0.45</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1F9KLZGHE9DTA</th>\n",
       "      <td>0.566667</td>\n",
       "      <td>1.418513</td>\n",
       "      <td>1.469431</td>\n",
       "      <td>1.379576</td>\n",
       "      <td>1.499780</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.293545</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.462215</td>\n",
       "      <td>0.45</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1LCUPRZ0I8S3I</th>\n",
       "      <td>0.633333</td>\n",
       "      <td>2.649913</td>\n",
       "      <td>2.984377</td>\n",
       "      <td>2.456276</td>\n",
       "      <td>2.447855</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.726375</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.775510</td>\n",
       "      <td>0.65</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1OOCYEFLAJD98</th>\n",
       "      <td>0.683333</td>\n",
       "      <td>2.343953</td>\n",
       "      <td>2.364995</td>\n",
       "      <td>4.215473</td>\n",
       "      <td>2.133665</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.373321</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.526340</td>\n",
       "      <td>0.60</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1U0FDPQ953KXX</th>\n",
       "      <td>0.683333</td>\n",
       "      <td>2.785461</td>\n",
       "      <td>2.953126</td>\n",
       "      <td>3.233671</td>\n",
       "      <td>2.932160</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3.165090</td>\n",
       "      <td>0.60</td>\n",
       "      <td>2.231432</td>\n",
       "      <td>0.70</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2ASRB2MTHDHPD</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.991117</td>\n",
       "      <td>3.284967</td>\n",
       "      <td>1.759483</td>\n",
       "      <td>2.114545</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.728868</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2.116825</td>\n",
       "      <td>0.55</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2M183CETUMR96</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>3.089463</td>\n",
       "      <td>3.843117</td>\n",
       "      <td>3.468331</td>\n",
       "      <td>2.946050</td>\n",
       "      <td>0.90</td>\n",
       "      <td>2.996610</td>\n",
       "      <td>0.90</td>\n",
       "      <td>3.323068</td>\n",
       "      <td>0.90</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3JJXDML3XNSQP</th>\n",
       "      <td>0.450000</td>\n",
       "      <td>3.407035</td>\n",
       "      <td>3.755030</td>\n",
       "      <td>6.430444</td>\n",
       "      <td>3.214316</td>\n",
       "      <td>0.30</td>\n",
       "      <td>3.324833</td>\n",
       "      <td>0.45</td>\n",
       "      <td>3.664100</td>\n",
       "      <td>0.60</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3RDT5DH21PVAR</th>\n",
       "      <td>0.416667</td>\n",
       "      <td>1.398958</td>\n",
       "      <td>1.180700</td>\n",
       "      <td>1.704520</td>\n",
       "      <td>1.312745</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.234080</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.650050</td>\n",
       "      <td>0.40</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3VHDQR8A9JJ4F</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.261107</td>\n",
       "      <td>1.207860</td>\n",
       "      <td>1.299140</td>\n",
       "      <td>1.261695</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.359075</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.162550</td>\n",
       "      <td>0.45</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A98E8M4QLI9RS</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.622333</td>\n",
       "      <td>1.542000</td>\n",
       "      <td>1.675889</td>\n",
       "      <td>1.706150</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.675100</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.485750</td>\n",
       "      <td>0.65</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AE33JO53WTHZQ</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>2.571715</td>\n",
       "      <td>2.570700</td>\n",
       "      <td>2.572150</td>\n",
       "      <td>2.428975</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.844180</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.441990</td>\n",
       "      <td>0.60</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK4WAT44YKU7J</th>\n",
       "      <td>0.783333</td>\n",
       "      <td>2.428318</td>\n",
       "      <td>2.267331</td>\n",
       "      <td>2.472847</td>\n",
       "      <td>2.452395</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.254125</td>\n",
       "      <td>0.85</td>\n",
       "      <td>2.578435</td>\n",
       "      <td>0.80</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMEBLCWTZKLS2</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>2.287683</td>\n",
       "      <td>2.439800</td>\n",
       "      <td>2.179029</td>\n",
       "      <td>2.148400</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.409650</td>\n",
       "      <td>0.55</td>\n",
       "      <td>2.305000</td>\n",
       "      <td>0.45</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATA61WNUAP91U</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>2.547673</td>\n",
       "      <td>2.430700</td>\n",
       "      <td>2.610659</td>\n",
       "      <td>2.755065</td>\n",
       "      <td>0.80</td>\n",
       "      <td>2.373785</td>\n",
       "      <td>0.65</td>\n",
       "      <td>2.514170</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                testing_Test_overall_accuracy  testing_RT_overall_mean  \\\n",
       "A11EXIB1MVBZFJ                       0.516667                 2.094241   \n",
       "A1F9KLZGHE9DTA                       0.566667                 1.418513   \n",
       "A1LCUPRZ0I8S3I                       0.633333                 2.649913   \n",
       "A1OOCYEFLAJD98                       0.683333                 2.343953   \n",
       "A1U0FDPQ953KXX                       0.683333                 2.785461   \n",
       "A2ASRB2MTHDHPD                       0.500000                 1.991117   \n",
       "A2M183CETUMR96                       0.900000                 3.089463   \n",
       "A3JJXDML3XNSQP                       0.450000                 3.407035   \n",
       "A3RDT5DH21PVAR                       0.416667                 1.398958   \n",
       "A3VHDQR8A9JJ4F                       0.583333                 1.261107   \n",
       "A98E8M4QLI9RS                        0.600000                 1.622333   \n",
       "AE33JO53WTHZQ                        0.700000                 2.571715   \n",
       "AK4WAT44YKU7J                        0.783333                 2.428318   \n",
       "AMEBLCWTZKLS2                        0.583333                 2.287683   \n",
       "ATA61WNUAP91U                        0.650000                 2.547673   \n",
       "\n",
       "                testing_RT_incorrect_mean  testing_RT_correct_mean  \\\n",
       "A11EXIB1MVBZFJ                   3.899862                12.155968   \n",
       "A1F9KLZGHE9DTA                   1.469431                 1.379576   \n",
       "A1LCUPRZ0I8S3I                   2.984377                 2.456276   \n",
       "A1OOCYEFLAJD98                   2.364995                 4.215473   \n",
       "A1U0FDPQ953KXX                   2.953126                 3.233671   \n",
       "A2ASRB2MTHDHPD                   3.284967                 1.759483   \n",
       "A2M183CETUMR96                   3.843117                 3.468331   \n",
       "A3JJXDML3XNSQP                   3.755030                 6.430444   \n",
       "A3RDT5DH21PVAR                   1.180700                 1.704520   \n",
       "A3VHDQR8A9JJ4F                   1.207860                 1.299140   \n",
       "A98E8M4QLI9RS                    1.542000                 1.675889   \n",
       "AE33JO53WTHZQ                    2.570700                 2.572150   \n",
       "AK4WAT44YKU7J                    2.267331                 2.472847   \n",
       "AMEBLCWTZKLS2                    2.439800                 2.179029   \n",
       "ATA61WNUAP91U                    2.430700                 2.610659   \n",
       "\n",
       "                testing_layer_1_rt  testing_layer_1_accuracy  \\\n",
       "A11EXIB1MVBZFJ            2.203368                      0.60   \n",
       "A1F9KLZGHE9DTA            1.499780                      0.65   \n",
       "A1LCUPRZ0I8S3I            2.447855                      0.75   \n",
       "A1OOCYEFLAJD98            2.133665                      0.75   \n",
       "A1U0FDPQ953KXX            2.932160                      0.75   \n",
       "A2ASRB2MTHDHPD            2.114545                      0.70   \n",
       "A2M183CETUMR96            2.946050                      0.90   \n",
       "A3JJXDML3XNSQP            3.214316                      0.30   \n",
       "A3RDT5DH21PVAR            1.312745                      0.50   \n",
       "A3VHDQR8A9JJ4F            1.261695                      0.60   \n",
       "A98E8M4QLI9RS             1.706150                      0.60   \n",
       "AE33JO53WTHZQ             2.428975                      0.75   \n",
       "AK4WAT44YKU7J             2.452395                      0.70   \n",
       "AMEBLCWTZKLS2             2.148400                      0.75   \n",
       "ATA61WNUAP91U             2.755065                      0.80   \n",
       "\n",
       "                testing_layer_2_rt  testing_layer_2_accuracy  \\\n",
       "A11EXIB1MVBZFJ            1.671950                      0.50   \n",
       "A1F9KLZGHE9DTA            1.293545                      0.60   \n",
       "A1LCUPRZ0I8S3I            2.726375                      0.50   \n",
       "A1OOCYEFLAJD98            2.373321                      0.70   \n",
       "A1U0FDPQ953KXX            3.165090                      0.60   \n",
       "A2ASRB2MTHDHPD            1.728868                      0.25   \n",
       "A2M183CETUMR96            2.996610                      0.90   \n",
       "A3JJXDML3XNSQP            3.324833                      0.45   \n",
       "A3RDT5DH21PVAR            1.234080                      0.35   \n",
       "A3VHDQR8A9JJ4F            1.359075                      0.70   \n",
       "A98E8M4QLI9RS             1.675100                      0.55   \n",
       "AE33JO53WTHZQ             2.844180                      0.75   \n",
       "AK4WAT44YKU7J             2.254125                      0.85   \n",
       "AMEBLCWTZKLS2             2.409650                      0.55   \n",
       "ATA61WNUAP91U             2.373785                      0.65   \n",
       "\n",
       "                testing_layer_3_rt  testing_layer_3_accuracy  \\\n",
       "A11EXIB1MVBZFJ            2.429632                      0.45   \n",
       "A1F9KLZGHE9DTA            1.462215                      0.45   \n",
       "A1LCUPRZ0I8S3I            2.775510                      0.65   \n",
       "A1OOCYEFLAJD98            2.526340                      0.60   \n",
       "A1U0FDPQ953KXX            2.231432                      0.70   \n",
       "A2ASRB2MTHDHPD            2.116825                      0.55   \n",
       "A2M183CETUMR96            3.323068                      0.90   \n",
       "A3JJXDML3XNSQP            3.664100                      0.60   \n",
       "A3RDT5DH21PVAR            1.650050                      0.40   \n",
       "A3VHDQR8A9JJ4F            1.162550                      0.45   \n",
       "A98E8M4QLI9RS             1.485750                      0.65   \n",
       "AE33JO53WTHZQ             2.441990                      0.60   \n",
       "AK4WAT44YKU7J             2.578435                      0.80   \n",
       "AMEBLCWTZKLS2             2.305000                      0.45   \n",
       "ATA61WNUAP91U             2.514170                      0.50   \n",
       "\n",
       "                testing_longest_response_strike  \n",
       "A11EXIB1MVBZFJ                              4.0  \n",
       "A1F9KLZGHE9DTA                              6.0  \n",
       "A1LCUPRZ0I8S3I                              4.0  \n",
       "A1OOCYEFLAJD98                              4.0  \n",
       "A1U0FDPQ953KXX                              3.0  \n",
       "A2ASRB2MTHDHPD                              9.0  \n",
       "A2M183CETUMR96                              5.0  \n",
       "A3JJXDML3XNSQP                              3.0  \n",
       "A3RDT5DH21PVAR                              4.0  \n",
       "A3VHDQR8A9JJ4F                              7.0  \n",
       "A98E8M4QLI9RS                               6.0  \n",
       "AE33JO53WTHZQ                               4.0  \n",
       "AK4WAT44YKU7J                               7.0  \n",
       "AMEBLCWTZKLS2                               3.0  \n",
       "ATA61WNUAP91U                               5.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this part extract summary information from the experiment testing phase: attention check accuracy and timings: \n",
    "all_subjects_summary_testing_info=pd.DataFrame(index=list(all_subjects_test_df['subject'].unique()))\n",
    "\n",
    "\n",
    "#this code calculates response time averages (RT) exlcusing the trials that are TOO long: \n",
    "trial_too_long_exclusion_criteria=10\n",
    "\n",
    "\n",
    "for cur_subject in all_subjects_test_df['subject'].unique():\n",
    "    cur_sub_testing=all_subjects_test_df.loc[all_subjects_test_df['subject']==cur_subject]\n",
    "\n",
    "    #get the correctness of the testing phase: \n",
    "    cur_sub_testing_performence=cur_sub_testing[['correct','test_test_response.keys','test_test_response.rt','layer','test_test_response.corr']].copy().dropna()\n",
    "\n",
    "\n",
    "    test_match_df=pd.DataFrame(columns=['correct'],data=cur_sub_testing_performence['correct']==cur_sub_testing_performence['test_test_response.keys'])\n",
    "    test_match_df['test_test_response.rt']=cur_sub_testing_performence['test_test_response.rt']\n",
    "    accuracy=test_match_df['correct'].mean()\n",
    "\n",
    "    # if there is one rt that is very long, lets not include it in the mean calculation \n",
    "    \n",
    "    mean_rt=(test_match_df.loc[test_match_df['test_test_response.rt']<=trial_too_long_exclusion_criteria,'test_test_response.rt']).mean()\n",
    "    correct_and_incorrect_rts_overall=test_match_df.groupby('correct').aggregate({'test_test_response.rt':'mean'})\n",
    "    \n",
    "    #update the summary info row: \n",
    "    all_subjects_summary_testing_info.loc[cur_subject,'Test_overall_accuracy']=accuracy\n",
    "    all_subjects_summary_testing_info.loc[cur_subject,'RT_overall_mean']=mean_rt\n",
    "    all_subjects_summary_testing_info.loc[cur_subject,['RT_incorrect_mean','RT_correct_mean']]=np.nan\n",
    "\n",
    "    if False in correct_and_incorrect_rts_overall.index:\n",
    "        all_subjects_summary_testing_info.loc[cur_subject,'RT_incorrect_mean']=correct_and_incorrect_rts_overall.loc[False].values[0]\n",
    "    if True in correct_and_incorrect_rts_overall.index:\n",
    "        all_subjects_summary_testing_info.loc[cur_subject,'RT_correct_mean']=correct_and_incorrect_rts_overall.loc[True].values[0]\n",
    "\n",
    "\n",
    "\n",
    "    #extract layer wise information (accuracy and rt):\n",
    "    cur_sub_testing_performence_copy=cur_sub_testing_performence.copy()\n",
    "    cur_sub_testing_performence_copy.loc[cur_sub_testing_performence_copy['test_test_response.rt']>trial_too_long_exclusion_criteria,'test_test_response.rt']=nan\n",
    "    correct_and_incorrect_rts=cur_sub_testing_performence_copy.groupby('layer').aggregate({'test_test_response.rt':'mean','test_test_response.corr':'mean'})\n",
    "    all_subjects_summary_testing_info.loc[cur_subject,['layer_1_rt','layer_1_accuracy','layer_2_rt','layer_2_accuracy','layer_3_rt','layer_3_accuracy']]=correct_and_incorrect_rts.values.flatten()\n",
    "\n",
    "\n",
    "    #check the longest structured strike (to find bots or very unattentive participants):\n",
    "    responses=cur_sub_testing_performence['test_test_response.keys'].replace({'left':1,'right':2}).values\n",
    "    max_iter=find_largest_consequtive_repetition(responses)\n",
    "\n",
    "    all_subjects_summary_testing_info.loc[cur_subject,'longest_response_strike']=max_iter\n",
    "\n",
    "#add a prefix to column names: \n",
    "all_subjects_summary_testing_info.columns=['testing_'+col for col in all_subjects_summary_testing_info.columns]        \n",
    "all_subjects_summary_testing_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct</th>\n",
       "      <th>test_test_response.keys</th>\n",
       "      <th>test_test_response.rt</th>\n",
       "      <th>layer</th>\n",
       "      <th>test_test_response.corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>2.8954</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.8464</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.8510</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.6270</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.9200</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.4969</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.4957</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>2.8855</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>3.1462</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.3710</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>2.0046</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.8653</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>3.5147</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.3726</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.7509</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>2.1360</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>3.2505</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.9870</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>2.8643</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>1.6243</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.2411</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>2.6363</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>2.3570</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>1.9731</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>2.2587</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>5.1742</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>2.1055</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>2.9254</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>2.4407</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>9.2838</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.7248</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>2.0479</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>3.8502</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>2.0291</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>8.5149</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.7867</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>2.7540</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>2.2552</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>1.6194</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.2638</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>2.5345</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>1.5056</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>6.6864</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.9968</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>5.0033</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.6450</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>1.4939</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>2.1803</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>4.8913</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.7712</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>2.0227</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.6791</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>1.7477</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.8178</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.9012</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.6761</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>2.1733</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.7636</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>3.1826</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>2.0409</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    correct test_test_response.keys  test_test_response.rt  layer  \\\n",
       "840    left                   right                 2.8954    1.0   \n",
       "841    left                    left                 1.8464    3.0   \n",
       "842   right                   right                 1.8510    3.0   \n",
       "843   right                   right                 1.6270    3.0   \n",
       "844    left                    left                 1.9200    2.0   \n",
       "845    left                    left                 1.4969    2.0   \n",
       "846    left                    left                 1.4957    1.0   \n",
       "847   right                    left                 2.8855    3.0   \n",
       "848   right                    left                 3.1462    3.0   \n",
       "849    left                    left                 1.3710    1.0   \n",
       "850    left                   right                 2.0046    3.0   \n",
       "851    left                    left                 1.8653    1.0   \n",
       "852    left                   right                 3.5147    1.0   \n",
       "853    left                    left                 1.3726    1.0   \n",
       "854    left                    left                 1.7509    3.0   \n",
       "855   right                    left                 2.1360    2.0   \n",
       "856    left                    left                 3.2505    1.0   \n",
       "857   right                   right                 1.9870    1.0   \n",
       "858    left                   right                 2.8643    2.0   \n",
       "859    left                   right                 1.6243    2.0   \n",
       "860    left                    left                 1.2411    2.0   \n",
       "861   right                    left                 2.6363    3.0   \n",
       "862    left                    left                 2.3570    2.0   \n",
       "863    left                   right                 1.9731    3.0   \n",
       "864   right                    left                 2.2587    1.0   \n",
       "865   right                   right                 5.1742    1.0   \n",
       "866    left                   right                 2.1055    3.0   \n",
       "867    left                    left                 2.9254    2.0   \n",
       "868    left                   right                 2.4407    2.0   \n",
       "869    left                    left                 9.2838    1.0   \n",
       "870    left                    left                 1.7248    2.0   \n",
       "871    left                    left                 2.0479    1.0   \n",
       "872    left                    left                 3.8502    2.0   \n",
       "873    left                    left                 2.0291    1.0   \n",
       "874    left                    left                 8.5149    2.0   \n",
       "875   right                   right                 1.7867    3.0   \n",
       "876   right                    left                 2.7540    3.0   \n",
       "877   right                    left                 2.2552    2.0   \n",
       "878   right                    left                 1.6194    3.0   \n",
       "879    left                    left                 1.2638    1.0   \n",
       "880    left                    left                 2.5345    3.0   \n",
       "881    left                   right                 1.5056    2.0   \n",
       "882   right                   right                 6.6864    3.0   \n",
       "883    left                    left                 1.9968    2.0   \n",
       "884   right                    left                 5.0033    3.0   \n",
       "885   right                   right                 1.6450    2.0   \n",
       "886   right                    left                 1.4939    2.0   \n",
       "887   right                    left                 2.1803    3.0   \n",
       "888   right                   right                 4.8913    1.0   \n",
       "889    left                    left                 1.7712    1.0   \n",
       "890    left                    left                 2.0227    1.0   \n",
       "891   right                   right                 1.6791    2.0   \n",
       "892    left                   right                 1.7477    1.0   \n",
       "893   right                   right                 1.8178    3.0   \n",
       "894   right                   right                 1.9012    3.0   \n",
       "895    left                    left                 1.6761    1.0   \n",
       "896    left                    left                 2.1733    3.0   \n",
       "897   right                   right                 1.7636    2.0   \n",
       "898    left                    left                 3.1826    1.0   \n",
       "899    left                    left                 2.0409    2.0   \n",
       "\n",
       "     test_test_response.corr  \n",
       "840                      0.0  \n",
       "841                      1.0  \n",
       "842                      1.0  \n",
       "843                      1.0  \n",
       "844                      1.0  \n",
       "845                      1.0  \n",
       "846                      1.0  \n",
       "847                      0.0  \n",
       "848                      0.0  \n",
       "849                      1.0  \n",
       "850                      0.0  \n",
       "851                      1.0  \n",
       "852                      0.0  \n",
       "853                      1.0  \n",
       "854                      1.0  \n",
       "855                      0.0  \n",
       "856                      1.0  \n",
       "857                      1.0  \n",
       "858                      0.0  \n",
       "859                      0.0  \n",
       "860                      1.0  \n",
       "861                      0.0  \n",
       "862                      1.0  \n",
       "863                      0.0  \n",
       "864                      0.0  \n",
       "865                      1.0  \n",
       "866                      0.0  \n",
       "867                      1.0  \n",
       "868                      0.0  \n",
       "869                      1.0  \n",
       "870                      1.0  \n",
       "871                      1.0  \n",
       "872                      1.0  \n",
       "873                      1.0  \n",
       "874                      1.0  \n",
       "875                      1.0  \n",
       "876                      0.0  \n",
       "877                      0.0  \n",
       "878                      0.0  \n",
       "879                      1.0  \n",
       "880                      1.0  \n",
       "881                      0.0  \n",
       "882                      1.0  \n",
       "883                      1.0  \n",
       "884                      0.0  \n",
       "885                      1.0  \n",
       "886                      0.0  \n",
       "887                      0.0  \n",
       "888                      1.0  \n",
       "889                      1.0  \n",
       "890                      1.0  \n",
       "891                      1.0  \n",
       "892                      0.0  \n",
       "893                      1.0  \n",
       "894                      1.0  \n",
       "895                      1.0  \n",
       "896                      1.0  \n",
       "897                      1.0  \n",
       "898                      1.0  \n",
       "899                      1.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_sub_testing_performence.loc[cur_sub_testing_performence['test_test_response.rt']>trial_too_long_exclusion_criteria,'test_test_response.rt']=nan\n",
    "cur_sub_testing_performence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5476733333333335"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outlier_responses(sub_test_dataframe,fast_threshold=0.1,fast_allowed_count=2,slow_threshold=10,slow_allowed_count=2):\n",
    "    isfast_outlier=(sub_test_dataframe['test_test_response.rt']<fast_threshold).sum()>fast_allowed_count\n",
    "    isslow_outlier=(sub_test_dataframe['test_test_response.rt']>slow_threshold).sum()>slow_allowed_count\n",
    "    return isfast_outlier,isslow_outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary for criterions:\n",
      "demo accuracy higher than 0.5 - qualified: 14\n",
      "demo attention check correctness equals 1 - qualified: 15\n",
      "experiment encoding attention check accuracy 0.6 - qualified: 14\n",
      "experiment longest consequtive strike of maximum of  15 responses - qualified: 15\n",
      "test too fast (thresold: 0.3, allowed count: 3 qualified: 15\n",
      "test too slow (thresold: 10, allowed count: 2 qualified: 13\n",
      "above chance accuracy in test, qualified: 8\n",
      "OVERALL: number of qualified participants (adhere to all criterions): 6\n"
     ]
    }
   ],
   "source": [
    "#combine all oneliners into a single matrix - 1 line per participant with all information we want:\n",
    "data_df_for_analysis=pd.concat([all_subjects_summary_demo_info,all_subjects_summary_encoding_info,all_subjects_summary_testing_info],axis=1)\n",
    "data_df_for_analysis\n",
    "\n",
    "\n",
    "#define thresholds: \n",
    "demo_accuracy_treshold=0.5\n",
    "demo_arrow_correctness=1\n",
    "encoding_arrow_accuracy=0.6\n",
    "longest_allowed_consequtive_strike=15\n",
    "fast_threshold=0.3\n",
    "fast_allowed_count=3\n",
    "slow_threshold=10\n",
    "slow_allowed_count=2\n",
    "\n",
    "\n",
    "#as each participant saw 20 distractors per layer, we need atleast 0.75 (15/20) accuracy in one of the layers or above 0.616 (37/60) in the overall: \n",
    "\n",
    "\n",
    "\n",
    "#how many participants would fail the demo (did not correctly answered the arrow or had less than 60% performence)\n",
    "demo_criterions_accuracy=data_df_for_analysis['demo_demo_accuracy']>=demo_accuracy_treshold\n",
    "demo_criterions_attention_check=data_df_for_analysis['demo_arrow_correct']>=demo_arrow_correctness\n",
    "#find which participants performed pooly on the attention checks of the experiment encoding phase: \n",
    "encoding_ciriterions=data_df_for_analysis['encoding_arrow_accuracy']>encoding_arrow_accuracy\n",
    "#remove participants that are too slow: \n",
    "test_criterions_strike=data_df_for_analysis['testing_longest_response_strike']<longest_allowed_consequtive_strike\n",
    "\n",
    "too_fast_criterions=[]\n",
    "too_slow_criterions=[]\n",
    "for subject in data_df_for_analysis.index:\n",
    "    sub_test_dataframe=all_subjects_test_df[all_subjects_test_df['subject']==subject]\n",
    "    toofast_criterion,tooslow_criterion=find_outlier_responses(sub_test_dataframe,fast_threshold=fast_threshold,fast_allowed_count=fast_allowed_count,slow_threshold=slow_threshold,slow_allowed_count=slow_allowed_count)\n",
    "    too_slow_criterions.append(not tooslow_criterion)\n",
    "    too_fast_criterions.append(not toofast_criterion)\n",
    "\n",
    "\n",
    "\n",
    "print(f'summary for criterions:')\n",
    "print(f'demo accuracy higher than {demo_accuracy_treshold} - qualified: {demo_criterions_accuracy.sum()}')\n",
    "print(f'demo attention check correctness equals {demo_arrow_correctness} - qualified: {demo_criterions_attention_check.sum()}')\n",
    "print(f'experiment encoding attention check accuracy {encoding_arrow_accuracy} - qualified: {encoding_ciriterions.sum()}')\n",
    "print(f'experiment longest consequtive strike of maximum of  {longest_allowed_consequtive_strike} responses - qualified: {test_criterions_strike.sum()}')\n",
    "print(f'test too fast (thresold: {fast_threshold}, allowed count: {fast_allowed_count} qualified: {sum(too_fast_criterions)}')\n",
    "print(f'test too slow (thresold: {slow_threshold}, allowed count: {slow_allowed_count} qualified: {sum(too_slow_criterions)}')\n",
    "#accuracy criterion on the test: \n",
    "test_accuracy_critertions=(data_df_for_analysis['testing_Test_overall_accuracy']>=0.61) | (data_df_for_analysis[['testing_layer_1_accuracy' ,'testing_layer_2_accuracy' ,'testing_layer_3_accuracy']]>=0.75).T.any()\n",
    "#remove participants that were discarded based on behavior up to the test and now qualify or disqualify based on test accuracy (do they have atleast 1 significant (binomial test) accuracy in one layer, or above threshold in overall accuracy )\n",
    "only_qualified=demo_criterions_accuracy & demo_criterions_attention_check & encoding_ciriterions & test_criterions_strike & too_fast_criterions & too_slow_criterions & test_accuracy_critertions\n",
    "print(f'above chance accuracy in test, qualified: {sum(test_accuracy_critertions)}')\n",
    "print(f'OVERALL: number of qualified participants (adhere to all criterions): {sum(only_qualified)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demo_arrow_rt</th>\n",
       "      <th>demo_arrow_correct</th>\n",
       "      <th>demo_demo_accuracy</th>\n",
       "      <th>demo_RT_overall_mean</th>\n",
       "      <th>demo_RT_incorrect_mean</th>\n",
       "      <th>demo_RT_correct_mean</th>\n",
       "      <th>encoding_arrow_mean_rt</th>\n",
       "      <th>encoding_arrow_accuracy</th>\n",
       "      <th>testing_Test_overall_accuracy</th>\n",
       "      <th>testing_RT_overall_mean</th>\n",
       "      <th>testing_RT_incorrect_mean</th>\n",
       "      <th>testing_RT_correct_mean</th>\n",
       "      <th>testing_layer_1_rt</th>\n",
       "      <th>testing_layer_1_accuracy</th>\n",
       "      <th>testing_layer_2_rt</th>\n",
       "      <th>testing_layer_2_accuracy</th>\n",
       "      <th>testing_layer_3_rt</th>\n",
       "      <th>testing_layer_3_accuracy</th>\n",
       "      <th>testing_longest_response_strike</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A11EXIB1MVBZFJ</th>\n",
       "      <td>1.1560</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.790667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.790667</td>\n",
       "      <td>1.13860</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>2.094241</td>\n",
       "      <td>3.899862</td>\n",
       "      <td>12.155968</td>\n",
       "      <td>2.203368</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.671950</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.429632</td>\n",
       "      <td>0.45</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1F9KLZGHE9DTA</th>\n",
       "      <td>0.5979</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.385950</td>\n",
       "      <td>1.740400</td>\n",
       "      <td>1.315060</td>\n",
       "      <td>0.59792</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>1.418513</td>\n",
       "      <td>1.469431</td>\n",
       "      <td>1.379576</td>\n",
       "      <td>1.499780</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.293545</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.462215</td>\n",
       "      <td>0.45</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1LCUPRZ0I8S3I</th>\n",
       "      <td>0.9871</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.185933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.185933</td>\n",
       "      <td>1.37952</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>2.649913</td>\n",
       "      <td>2.984377</td>\n",
       "      <td>2.456276</td>\n",
       "      <td>2.447855</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.726375</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.775510</td>\n",
       "      <td>0.65</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1OOCYEFLAJD98</th>\n",
       "      <td>0.5116</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.427583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.427583</td>\n",
       "      <td>0.67562</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>2.343953</td>\n",
       "      <td>2.364995</td>\n",
       "      <td>4.215473</td>\n",
       "      <td>2.133665</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.373321</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.526340</td>\n",
       "      <td>0.60</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1U0FDPQ953KXX</th>\n",
       "      <td>1.1286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>5.252667</td>\n",
       "      <td>3.311800</td>\n",
       "      <td>5.640840</td>\n",
       "      <td>1.30840</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>2.785461</td>\n",
       "      <td>2.953126</td>\n",
       "      <td>3.233671</td>\n",
       "      <td>2.932160</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3.165090</td>\n",
       "      <td>0.60</td>\n",
       "      <td>2.231432</td>\n",
       "      <td>0.70</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2ASRB2MTHDHPD</th>\n",
       "      <td>1.2799</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.293650</td>\n",
       "      <td>4.709733</td>\n",
       "      <td>5.877567</td>\n",
       "      <td>1.63130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.991117</td>\n",
       "      <td>3.284967</td>\n",
       "      <td>1.759483</td>\n",
       "      <td>2.114545</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.728868</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2.116825</td>\n",
       "      <td>0.55</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2M183CETUMR96</th>\n",
       "      <td>0.5185</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>5.864933</td>\n",
       "      <td>3.148550</td>\n",
       "      <td>11.297700</td>\n",
       "      <td>0.48240</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>3.089463</td>\n",
       "      <td>3.843117</td>\n",
       "      <td>3.468331</td>\n",
       "      <td>2.946050</td>\n",
       "      <td>0.90</td>\n",
       "      <td>2.996610</td>\n",
       "      <td>0.90</td>\n",
       "      <td>3.323068</td>\n",
       "      <td>0.90</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3JJXDML3XNSQP</th>\n",
       "      <td>1.8620</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>5.357000</td>\n",
       "      <td>15.925000</td>\n",
       "      <td>3.243400</td>\n",
       "      <td>1.37120</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>3.407035</td>\n",
       "      <td>3.755030</td>\n",
       "      <td>6.430444</td>\n",
       "      <td>3.214316</td>\n",
       "      <td>0.30</td>\n",
       "      <td>3.324833</td>\n",
       "      <td>0.45</td>\n",
       "      <td>3.664100</td>\n",
       "      <td>0.60</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3RDT5DH21PVAR</th>\n",
       "      <td>2.1221</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.208033</td>\n",
       "      <td>1.722100</td>\n",
       "      <td>2.451000</td>\n",
       "      <td>1.14476</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>1.398958</td>\n",
       "      <td>1.180700</td>\n",
       "      <td>1.704520</td>\n",
       "      <td>1.312745</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.234080</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.650050</td>\n",
       "      <td>0.40</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3VHDQR8A9JJ4F</th>\n",
       "      <td>0.6487</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.888650</td>\n",
       "      <td>1.807700</td>\n",
       "      <td>1.904840</td>\n",
       "      <td>0.62064</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.261107</td>\n",
       "      <td>1.207860</td>\n",
       "      <td>1.299140</td>\n",
       "      <td>1.261695</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.359075</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.162550</td>\n",
       "      <td>0.45</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A98E8M4QLI9RS</th>\n",
       "      <td>0.4490</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.305167</td>\n",
       "      <td>1.206000</td>\n",
       "      <td>1.354750</td>\n",
       "      <td>0.59220</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.622333</td>\n",
       "      <td>1.542000</td>\n",
       "      <td>1.675889</td>\n",
       "      <td>1.706150</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.675100</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.485750</td>\n",
       "      <td>0.65</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AE33JO53WTHZQ</th>\n",
       "      <td>1.3502</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>4.566183</td>\n",
       "      <td>4.398000</td>\n",
       "      <td>4.650275</td>\n",
       "      <td>1.10420</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>2.571715</td>\n",
       "      <td>2.570700</td>\n",
       "      <td>2.572150</td>\n",
       "      <td>2.428975</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.844180</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.441990</td>\n",
       "      <td>0.60</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK4WAT44YKU7J</th>\n",
       "      <td>0.6394</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.239683</td>\n",
       "      <td>2.574500</td>\n",
       "      <td>2.072275</td>\n",
       "      <td>0.52266</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>2.428318</td>\n",
       "      <td>2.267331</td>\n",
       "      <td>2.472847</td>\n",
       "      <td>2.452395</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.254125</td>\n",
       "      <td>0.85</td>\n",
       "      <td>2.578435</td>\n",
       "      <td>0.80</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMEBLCWTZKLS2</th>\n",
       "      <td>0.9730</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.663333</td>\n",
       "      <td>1.395000</td>\n",
       "      <td>1.717000</td>\n",
       "      <td>1.03720</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>2.287683</td>\n",
       "      <td>2.439800</td>\n",
       "      <td>2.179029</td>\n",
       "      <td>2.148400</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.409650</td>\n",
       "      <td>0.55</td>\n",
       "      <td>2.305000</td>\n",
       "      <td>0.45</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATA61WNUAP91U</th>\n",
       "      <td>1.3853</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>2.389683</td>\n",
       "      <td>2.182800</td>\n",
       "      <td>2.431060</td>\n",
       "      <td>1.27288</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>2.547673</td>\n",
       "      <td>2.430700</td>\n",
       "      <td>2.610659</td>\n",
       "      <td>2.755065</td>\n",
       "      <td>0.80</td>\n",
       "      <td>2.373785</td>\n",
       "      <td>0.65</td>\n",
       "      <td>2.514170</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                demo_arrow_rt  demo_arrow_correct  demo_demo_accuracy  \\\n",
       "A11EXIB1MVBZFJ         1.1560                 1.0            1.000000   \n",
       "A1F9KLZGHE9DTA         0.5979                 1.0            0.833333   \n",
       "A1LCUPRZ0I8S3I         0.9871                 1.0            1.000000   \n",
       "A1OOCYEFLAJD98         0.5116                 1.0            1.000000   \n",
       "A1U0FDPQ953KXX         1.1286                 1.0            0.833333   \n",
       "A2ASRB2MTHDHPD         1.2799                 1.0            0.500000   \n",
       "A2M183CETUMR96         0.5185                 1.0            0.333333   \n",
       "A3JJXDML3XNSQP         1.8620                 1.0            0.833333   \n",
       "A3RDT5DH21PVAR         2.1221                 1.0            0.666667   \n",
       "A3VHDQR8A9JJ4F         0.6487                 1.0            0.833333   \n",
       "A98E8M4QLI9RS          0.4490                 1.0            0.666667   \n",
       "AE33JO53WTHZQ          1.3502                 1.0            0.666667   \n",
       "AK4WAT44YKU7J          0.6394                 1.0            0.666667   \n",
       "AMEBLCWTZKLS2          0.9730                 1.0            0.833333   \n",
       "ATA61WNUAP91U          1.3853                 1.0            0.833333   \n",
       "\n",
       "                demo_RT_overall_mean  demo_RT_incorrect_mean  \\\n",
       "A11EXIB1MVBZFJ             15.790667                     NaN   \n",
       "A1F9KLZGHE9DTA              1.385950                1.740400   \n",
       "A1LCUPRZ0I8S3I              2.185933                     NaN   \n",
       "A1OOCYEFLAJD98              2.427583                     NaN   \n",
       "A1U0FDPQ953KXX              5.252667                3.311800   \n",
       "A2ASRB2MTHDHPD              5.293650                4.709733   \n",
       "A2M183CETUMR96              5.864933                3.148550   \n",
       "A3JJXDML3XNSQP              5.357000               15.925000   \n",
       "A3RDT5DH21PVAR              2.208033                1.722100   \n",
       "A3VHDQR8A9JJ4F              1.888650                1.807700   \n",
       "A98E8M4QLI9RS               1.305167                1.206000   \n",
       "AE33JO53WTHZQ               4.566183                4.398000   \n",
       "AK4WAT44YKU7J               2.239683                2.574500   \n",
       "AMEBLCWTZKLS2               1.663333                1.395000   \n",
       "ATA61WNUAP91U               2.389683                2.182800   \n",
       "\n",
       "                demo_RT_correct_mean  encoding_arrow_mean_rt  \\\n",
       "A11EXIB1MVBZFJ             15.790667                 1.13860   \n",
       "A1F9KLZGHE9DTA              1.315060                 0.59792   \n",
       "A1LCUPRZ0I8S3I              2.185933                 1.37952   \n",
       "A1OOCYEFLAJD98              2.427583                 0.67562   \n",
       "A1U0FDPQ953KXX              5.640840                 1.30840   \n",
       "A2ASRB2MTHDHPD              5.877567                 1.63130   \n",
       "A2M183CETUMR96             11.297700                 0.48240   \n",
       "A3JJXDML3XNSQP              3.243400                 1.37120   \n",
       "A3RDT5DH21PVAR              2.451000                 1.14476   \n",
       "A3VHDQR8A9JJ4F              1.904840                 0.62064   \n",
       "A98E8M4QLI9RS               1.354750                 0.59220   \n",
       "AE33JO53WTHZQ               4.650275                 1.10420   \n",
       "AK4WAT44YKU7J               2.072275                 0.52266   \n",
       "AMEBLCWTZKLS2               1.717000                 1.03720   \n",
       "ATA61WNUAP91U               2.431060                 1.27288   \n",
       "\n",
       "                encoding_arrow_accuracy  testing_Test_overall_accuracy  \\\n",
       "A11EXIB1MVBZFJ                      1.0                       0.516667   \n",
       "A1F9KLZGHE9DTA                      1.0                       0.566667   \n",
       "A1LCUPRZ0I8S3I                      1.0                       0.633333   \n",
       "A1OOCYEFLAJD98                      1.0                       0.683333   \n",
       "A1U0FDPQ953KXX                      1.0                       0.683333   \n",
       "A2ASRB2MTHDHPD                      1.0                       0.500000   \n",
       "A2M183CETUMR96                      1.0                       0.900000   \n",
       "A3JJXDML3XNSQP                      1.0                       0.450000   \n",
       "A3RDT5DH21PVAR                      0.8                       0.416667   \n",
       "A3VHDQR8A9JJ4F                      1.0                       0.583333   \n",
       "A98E8M4QLI9RS                       1.0                       0.600000   \n",
       "AE33JO53WTHZQ                       0.6                       0.700000   \n",
       "AK4WAT44YKU7J                       1.0                       0.783333   \n",
       "AMEBLCWTZKLS2                       1.0                       0.583333   \n",
       "ATA61WNUAP91U                       1.0                       0.650000   \n",
       "\n",
       "                testing_RT_overall_mean  testing_RT_incorrect_mean  \\\n",
       "A11EXIB1MVBZFJ                 2.094241                   3.899862   \n",
       "A1F9KLZGHE9DTA                 1.418513                   1.469431   \n",
       "A1LCUPRZ0I8S3I                 2.649913                   2.984377   \n",
       "A1OOCYEFLAJD98                 2.343953                   2.364995   \n",
       "A1U0FDPQ953KXX                 2.785461                   2.953126   \n",
       "A2ASRB2MTHDHPD                 1.991117                   3.284967   \n",
       "A2M183CETUMR96                 3.089463                   3.843117   \n",
       "A3JJXDML3XNSQP                 3.407035                   3.755030   \n",
       "A3RDT5DH21PVAR                 1.398958                   1.180700   \n",
       "A3VHDQR8A9JJ4F                 1.261107                   1.207860   \n",
       "A98E8M4QLI9RS                  1.622333                   1.542000   \n",
       "AE33JO53WTHZQ                  2.571715                   2.570700   \n",
       "AK4WAT44YKU7J                  2.428318                   2.267331   \n",
       "AMEBLCWTZKLS2                  2.287683                   2.439800   \n",
       "ATA61WNUAP91U                  2.547673                   2.430700   \n",
       "\n",
       "                testing_RT_correct_mean  testing_layer_1_rt  \\\n",
       "A11EXIB1MVBZFJ                12.155968            2.203368   \n",
       "A1F9KLZGHE9DTA                 1.379576            1.499780   \n",
       "A1LCUPRZ0I8S3I                 2.456276            2.447855   \n",
       "A1OOCYEFLAJD98                 4.215473            2.133665   \n",
       "A1U0FDPQ953KXX                 3.233671            2.932160   \n",
       "A2ASRB2MTHDHPD                 1.759483            2.114545   \n",
       "A2M183CETUMR96                 3.468331            2.946050   \n",
       "A3JJXDML3XNSQP                 6.430444            3.214316   \n",
       "A3RDT5DH21PVAR                 1.704520            1.312745   \n",
       "A3VHDQR8A9JJ4F                 1.299140            1.261695   \n",
       "A98E8M4QLI9RS                  1.675889            1.706150   \n",
       "AE33JO53WTHZQ                  2.572150            2.428975   \n",
       "AK4WAT44YKU7J                  2.472847            2.452395   \n",
       "AMEBLCWTZKLS2                  2.179029            2.148400   \n",
       "ATA61WNUAP91U                  2.610659            2.755065   \n",
       "\n",
       "                testing_layer_1_accuracy  testing_layer_2_rt  \\\n",
       "A11EXIB1MVBZFJ                      0.60            1.671950   \n",
       "A1F9KLZGHE9DTA                      0.65            1.293545   \n",
       "A1LCUPRZ0I8S3I                      0.75            2.726375   \n",
       "A1OOCYEFLAJD98                      0.75            2.373321   \n",
       "A1U0FDPQ953KXX                      0.75            3.165090   \n",
       "A2ASRB2MTHDHPD                      0.70            1.728868   \n",
       "A2M183CETUMR96                      0.90            2.996610   \n",
       "A3JJXDML3XNSQP                      0.30            3.324833   \n",
       "A3RDT5DH21PVAR                      0.50            1.234080   \n",
       "A3VHDQR8A9JJ4F                      0.60            1.359075   \n",
       "A98E8M4QLI9RS                       0.60            1.675100   \n",
       "AE33JO53WTHZQ                       0.75            2.844180   \n",
       "AK4WAT44YKU7J                       0.70            2.254125   \n",
       "AMEBLCWTZKLS2                       0.75            2.409650   \n",
       "ATA61WNUAP91U                       0.80            2.373785   \n",
       "\n",
       "                testing_layer_2_accuracy  testing_layer_3_rt  \\\n",
       "A11EXIB1MVBZFJ                      0.50            2.429632   \n",
       "A1F9KLZGHE9DTA                      0.60            1.462215   \n",
       "A1LCUPRZ0I8S3I                      0.50            2.775510   \n",
       "A1OOCYEFLAJD98                      0.70            2.526340   \n",
       "A1U0FDPQ953KXX                      0.60            2.231432   \n",
       "A2ASRB2MTHDHPD                      0.25            2.116825   \n",
       "A2M183CETUMR96                      0.90            3.323068   \n",
       "A3JJXDML3XNSQP                      0.45            3.664100   \n",
       "A3RDT5DH21PVAR                      0.35            1.650050   \n",
       "A3VHDQR8A9JJ4F                      0.70            1.162550   \n",
       "A98E8M4QLI9RS                       0.55            1.485750   \n",
       "AE33JO53WTHZQ                       0.75            2.441990   \n",
       "AK4WAT44YKU7J                       0.85            2.578435   \n",
       "AMEBLCWTZKLS2                       0.55            2.305000   \n",
       "ATA61WNUAP91U                       0.65            2.514170   \n",
       "\n",
       "                testing_layer_3_accuracy  testing_longest_response_strike  \n",
       "A11EXIB1MVBZFJ                      0.45                              4.0  \n",
       "A1F9KLZGHE9DTA                      0.45                              6.0  \n",
       "A1LCUPRZ0I8S3I                      0.65                              4.0  \n",
       "A1OOCYEFLAJD98                      0.60                              4.0  \n",
       "A1U0FDPQ953KXX                      0.70                              3.0  \n",
       "A2ASRB2MTHDHPD                      0.55                              9.0  \n",
       "A2M183CETUMR96                      0.90                              5.0  \n",
       "A3JJXDML3XNSQP                      0.60                              3.0  \n",
       "A3RDT5DH21PVAR                      0.40                              4.0  \n",
       "A3VHDQR8A9JJ4F                      0.45                              7.0  \n",
       "A98E8M4QLI9RS                       0.65                              6.0  \n",
       "AE33JO53WTHZQ                       0.60                              4.0  \n",
       "AK4WAT44YKU7J                       0.80                              7.0  \n",
       "AMEBLCWTZKLS2                       0.45                              3.0  \n",
       "ATA61WNUAP91U                       0.50                              5.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df_for_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demo_demo_accuracy</th>\n",
       "      <th>demo_arrow_correct</th>\n",
       "      <th>encoding_arrow_accuracy</th>\n",
       "      <th>testing_longest_response_strike</th>\n",
       "      <th>not_too_slow</th>\n",
       "      <th>not_too_Fast</th>\n",
       "      <th>sufficient_test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A11EXIB1MVBZFJ</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1F9KLZGHE9DTA</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1LCUPRZ0I8S3I</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1OOCYEFLAJD98</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1U0FDPQ953KXX</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2ASRB2MTHDHPD</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2M183CETUMR96</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3JJXDML3XNSQP</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3RDT5DH21PVAR</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3VHDQR8A9JJ4F</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A98E8M4QLI9RS</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AE33JO53WTHZQ</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK4WAT44YKU7J</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMEBLCWTZKLS2</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATA61WNUAP91U</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                demo_demo_accuracy  demo_arrow_correct  \\\n",
       "A11EXIB1MVBZFJ                True                True   \n",
       "A1F9KLZGHE9DTA                True                True   \n",
       "A1LCUPRZ0I8S3I                True                True   \n",
       "A1OOCYEFLAJD98                True                True   \n",
       "A1U0FDPQ953KXX                True                True   \n",
       "A2ASRB2MTHDHPD                True                True   \n",
       "A2M183CETUMR96               False                True   \n",
       "A3JJXDML3XNSQP                True                True   \n",
       "A3RDT5DH21PVAR                True                True   \n",
       "A3VHDQR8A9JJ4F                True                True   \n",
       "A98E8M4QLI9RS                 True                True   \n",
       "AE33JO53WTHZQ                 True                True   \n",
       "AK4WAT44YKU7J                 True                True   \n",
       "AMEBLCWTZKLS2                 True                True   \n",
       "ATA61WNUAP91U                 True                True   \n",
       "\n",
       "                encoding_arrow_accuracy  testing_longest_response_strike  \\\n",
       "A11EXIB1MVBZFJ                     True                             True   \n",
       "A1F9KLZGHE9DTA                     True                             True   \n",
       "A1LCUPRZ0I8S3I                     True                             True   \n",
       "A1OOCYEFLAJD98                     True                             True   \n",
       "A1U0FDPQ953KXX                     True                             True   \n",
       "A2ASRB2MTHDHPD                     True                             True   \n",
       "A2M183CETUMR96                     True                             True   \n",
       "A3JJXDML3XNSQP                     True                             True   \n",
       "A3RDT5DH21PVAR                     True                             True   \n",
       "A3VHDQR8A9JJ4F                     True                             True   \n",
       "A98E8M4QLI9RS                      True                             True   \n",
       "AE33JO53WTHZQ                     False                             True   \n",
       "AK4WAT44YKU7J                      True                             True   \n",
       "AMEBLCWTZKLS2                      True                             True   \n",
       "ATA61WNUAP91U                      True                             True   \n",
       "\n",
       "                not_too_slow  not_too_Fast  sufficient_test_acc  \n",
       "A11EXIB1MVBZFJ          True          True                False  \n",
       "A1F9KLZGHE9DTA          True          True                False  \n",
       "A1LCUPRZ0I8S3I          True          True                 True  \n",
       "A1OOCYEFLAJD98          True          True                 True  \n",
       "A1U0FDPQ953KXX          True          True                 True  \n",
       "A2ASRB2MTHDHPD          True          True                False  \n",
       "A2M183CETUMR96         False          True                 True  \n",
       "A3JJXDML3XNSQP         False          True                False  \n",
       "A3RDT5DH21PVAR          True          True                False  \n",
       "A3VHDQR8A9JJ4F          True          True                False  \n",
       "A98E8M4QLI9RS           True          True                False  \n",
       "AE33JO53WTHZQ           True          True                 True  \n",
       "AK4WAT44YKU7J           True          True                 True  \n",
       "AMEBLCWTZKLS2           True          True                 True  \n",
       "ATA61WNUAP91U           True          True                 True  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#update the batch_workers_df  with columns representing disqualification reasons: \n",
    "tooslow_df=pd.DataFrame(data=too_slow_criterions,index=data_df_for_analysis.index,columns=['not_too_slow'])\n",
    "toofast_df=pd.DataFrame(data=too_fast_criterions,index=data_df_for_analysis.index,columns=['not_too_Fast'])\n",
    "test_accuracy_critertions=pd.DataFrame(data=test_accuracy_critertions,index=data_df_for_analysis.index, columns=['sufficient_test_acc'])\n",
    "disqualification_df=pd.concat([demo_criterions_accuracy,demo_criterions_attention_check,encoding_ciriterions,test_criterions_strike,tooslow_df,toofast_df,test_accuracy_critertions],axis=1)\n",
    "disqualification_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge workers_df with disqualification and save: \n",
    "index_list=[ind.split('_')[0] for ind in disqualification_df.index]\n",
    "disqualification_df['WorkerId']=index_list\n",
    "\n",
    "batch_workers_df_extended = workers_df.merge(disqualification_df, left_on='Worker ID', right_on='WorkerId', how = 'inner')\n",
    "batch_workers_df_extended = workers_df.merge(disqualification_df, left_on='Worker ID', right_on='WorkerId', how = 'outer')\n",
    "\n",
    "#add qualification column: (currently any participant will get this qualification (even if he just openneded the experiment and quit, because we dont want him back)\n",
    "qualification_colname='UPDATE-completed memory rep'\n",
    "batch_workers_df_extended[qualification_colname]=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demo_arrow_rt</th>\n",
       "      <th>demo_arrow_correct</th>\n",
       "      <th>demo_demo_accuracy</th>\n",
       "      <th>demo_RT_overall_mean</th>\n",
       "      <th>demo_RT_incorrect_mean</th>\n",
       "      <th>demo_RT_correct_mean</th>\n",
       "      <th>encoding_arrow_mean_rt</th>\n",
       "      <th>encoding_arrow_accuracy</th>\n",
       "      <th>testing_Test_overall_accuracy</th>\n",
       "      <th>testing_RT_overall_mean</th>\n",
       "      <th>testing_RT_incorrect_mean</th>\n",
       "      <th>testing_RT_correct_mean</th>\n",
       "      <th>testing_layer_1_rt</th>\n",
       "      <th>testing_layer_1_accuracy</th>\n",
       "      <th>testing_layer_2_rt</th>\n",
       "      <th>testing_layer_2_accuracy</th>\n",
       "      <th>testing_layer_3_rt</th>\n",
       "      <th>testing_layer_3_accuracy</th>\n",
       "      <th>testing_longest_response_strike</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A1LCUPRZ0I8S3I</th>\n",
       "      <td>0.9871</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.185933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.185933</td>\n",
       "      <td>1.37952</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>2.649913</td>\n",
       "      <td>2.984377</td>\n",
       "      <td>2.456276</td>\n",
       "      <td>2.447855</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.726375</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.775510</td>\n",
       "      <td>0.65</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1OOCYEFLAJD98</th>\n",
       "      <td>0.5116</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.427583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.427583</td>\n",
       "      <td>0.67562</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>2.343953</td>\n",
       "      <td>2.364995</td>\n",
       "      <td>4.215473</td>\n",
       "      <td>2.133665</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.373321</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.526340</td>\n",
       "      <td>0.60</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1U0FDPQ953KXX</th>\n",
       "      <td>1.1286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>5.252667</td>\n",
       "      <td>3.3118</td>\n",
       "      <td>5.640840</td>\n",
       "      <td>1.30840</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>2.785461</td>\n",
       "      <td>2.953126</td>\n",
       "      <td>3.233671</td>\n",
       "      <td>2.932160</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3.165090</td>\n",
       "      <td>0.60</td>\n",
       "      <td>2.231432</td>\n",
       "      <td>0.70</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK4WAT44YKU7J</th>\n",
       "      <td>0.6394</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.239683</td>\n",
       "      <td>2.5745</td>\n",
       "      <td>2.072275</td>\n",
       "      <td>0.52266</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>2.428318</td>\n",
       "      <td>2.267331</td>\n",
       "      <td>2.472847</td>\n",
       "      <td>2.452395</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.254125</td>\n",
       "      <td>0.85</td>\n",
       "      <td>2.578435</td>\n",
       "      <td>0.80</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMEBLCWTZKLS2</th>\n",
       "      <td>0.9730</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.663333</td>\n",
       "      <td>1.3950</td>\n",
       "      <td>1.717000</td>\n",
       "      <td>1.03720</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>2.287683</td>\n",
       "      <td>2.439800</td>\n",
       "      <td>2.179029</td>\n",
       "      <td>2.148400</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.409650</td>\n",
       "      <td>0.55</td>\n",
       "      <td>2.305000</td>\n",
       "      <td>0.45</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATA61WNUAP91U</th>\n",
       "      <td>1.3853</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>2.389683</td>\n",
       "      <td>2.1828</td>\n",
       "      <td>2.431060</td>\n",
       "      <td>1.27288</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>2.547673</td>\n",
       "      <td>2.430700</td>\n",
       "      <td>2.610659</td>\n",
       "      <td>2.755065</td>\n",
       "      <td>0.80</td>\n",
       "      <td>2.373785</td>\n",
       "      <td>0.65</td>\n",
       "      <td>2.514170</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                demo_arrow_rt  demo_arrow_correct  demo_demo_accuracy  \\\n",
       "A1LCUPRZ0I8S3I         0.9871                 1.0            1.000000   \n",
       "A1OOCYEFLAJD98         0.5116                 1.0            1.000000   \n",
       "A1U0FDPQ953KXX         1.1286                 1.0            0.833333   \n",
       "AK4WAT44YKU7J          0.6394                 1.0            0.666667   \n",
       "AMEBLCWTZKLS2          0.9730                 1.0            0.833333   \n",
       "ATA61WNUAP91U          1.3853                 1.0            0.833333   \n",
       "\n",
       "                demo_RT_overall_mean  demo_RT_incorrect_mean  \\\n",
       "A1LCUPRZ0I8S3I              2.185933                     NaN   \n",
       "A1OOCYEFLAJD98              2.427583                     NaN   \n",
       "A1U0FDPQ953KXX              5.252667                  3.3118   \n",
       "AK4WAT44YKU7J               2.239683                  2.5745   \n",
       "AMEBLCWTZKLS2               1.663333                  1.3950   \n",
       "ATA61WNUAP91U               2.389683                  2.1828   \n",
       "\n",
       "                demo_RT_correct_mean  encoding_arrow_mean_rt  \\\n",
       "A1LCUPRZ0I8S3I              2.185933                 1.37952   \n",
       "A1OOCYEFLAJD98              2.427583                 0.67562   \n",
       "A1U0FDPQ953KXX              5.640840                 1.30840   \n",
       "AK4WAT44YKU7J               2.072275                 0.52266   \n",
       "AMEBLCWTZKLS2               1.717000                 1.03720   \n",
       "ATA61WNUAP91U               2.431060                 1.27288   \n",
       "\n",
       "                encoding_arrow_accuracy  testing_Test_overall_accuracy  \\\n",
       "A1LCUPRZ0I8S3I                      1.0                       0.633333   \n",
       "A1OOCYEFLAJD98                      1.0                       0.683333   \n",
       "A1U0FDPQ953KXX                      1.0                       0.683333   \n",
       "AK4WAT44YKU7J                       1.0                       0.783333   \n",
       "AMEBLCWTZKLS2                       1.0                       0.583333   \n",
       "ATA61WNUAP91U                       1.0                       0.650000   \n",
       "\n",
       "                testing_RT_overall_mean  testing_RT_incorrect_mean  \\\n",
       "A1LCUPRZ0I8S3I                 2.649913                   2.984377   \n",
       "A1OOCYEFLAJD98                 2.343953                   2.364995   \n",
       "A1U0FDPQ953KXX                 2.785461                   2.953126   \n",
       "AK4WAT44YKU7J                  2.428318                   2.267331   \n",
       "AMEBLCWTZKLS2                  2.287683                   2.439800   \n",
       "ATA61WNUAP91U                  2.547673                   2.430700   \n",
       "\n",
       "                testing_RT_correct_mean  testing_layer_1_rt  \\\n",
       "A1LCUPRZ0I8S3I                 2.456276            2.447855   \n",
       "A1OOCYEFLAJD98                 4.215473            2.133665   \n",
       "A1U0FDPQ953KXX                 3.233671            2.932160   \n",
       "AK4WAT44YKU7J                  2.472847            2.452395   \n",
       "AMEBLCWTZKLS2                  2.179029            2.148400   \n",
       "ATA61WNUAP91U                  2.610659            2.755065   \n",
       "\n",
       "                testing_layer_1_accuracy  testing_layer_2_rt  \\\n",
       "A1LCUPRZ0I8S3I                      0.75            2.726375   \n",
       "A1OOCYEFLAJD98                      0.75            2.373321   \n",
       "A1U0FDPQ953KXX                      0.75            3.165090   \n",
       "AK4WAT44YKU7J                       0.70            2.254125   \n",
       "AMEBLCWTZKLS2                       0.75            2.409650   \n",
       "ATA61WNUAP91U                       0.80            2.373785   \n",
       "\n",
       "                testing_layer_2_accuracy  testing_layer_3_rt  \\\n",
       "A1LCUPRZ0I8S3I                      0.50            2.775510   \n",
       "A1OOCYEFLAJD98                      0.70            2.526340   \n",
       "A1U0FDPQ953KXX                      0.60            2.231432   \n",
       "AK4WAT44YKU7J                       0.85            2.578435   \n",
       "AMEBLCWTZKLS2                       0.55            2.305000   \n",
       "ATA61WNUAP91U                       0.65            2.514170   \n",
       "\n",
       "                testing_layer_3_accuracy  testing_longest_response_strike  \n",
       "A1LCUPRZ0I8S3I                      0.65                              4.0  \n",
       "A1OOCYEFLAJD98                      0.60                              4.0  \n",
       "A1U0FDPQ953KXX                      0.70                              3.0  \n",
       "AK4WAT44YKU7J                       0.80                              7.0  \n",
       "AMEBLCWTZKLS2                       0.45                              3.0  \n",
       "ATA61WNUAP91U                       0.50                              5.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract data that passes all criterions: \n",
    "final_participants_df=data_df_for_analysis[only_qualified]\n",
    "final_participants_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demo_arrow_rt</th>\n",
       "      <th>demo_arrow_correct</th>\n",
       "      <th>demo_demo_accuracy</th>\n",
       "      <th>demo_RT_overall_mean</th>\n",
       "      <th>demo_RT_incorrect_mean</th>\n",
       "      <th>demo_RT_correct_mean</th>\n",
       "      <th>encoding_arrow_mean_rt</th>\n",
       "      <th>encoding_arrow_accuracy</th>\n",
       "      <th>testing_Test_overall_accuracy</th>\n",
       "      <th>testing_RT_overall_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>testing_layer_3_accuracy</th>\n",
       "      <th>testing_longest_response_strike</th>\n",
       "      <th>demo_demo_accuracy</th>\n",
       "      <th>demo_arrow_correct</th>\n",
       "      <th>encoding_arrow_accuracy</th>\n",
       "      <th>testing_longest_response_strike</th>\n",
       "      <th>not_too_slow</th>\n",
       "      <th>not_too_Fast</th>\n",
       "      <th>sufficient_test_acc</th>\n",
       "      <th>WorkerId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A11EXIB1MVBZFJ</th>\n",
       "      <td>1.1560</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.790667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.790667</td>\n",
       "      <td>1.13860</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>2.094241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>A11EXIB1MVBZFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1F9KLZGHE9DTA</th>\n",
       "      <td>0.5979</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.385950</td>\n",
       "      <td>1.7404</td>\n",
       "      <td>1.315060</td>\n",
       "      <td>0.59792</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>1.418513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>A1F9KLZGHE9DTA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1LCUPRZ0I8S3I</th>\n",
       "      <td>0.9871</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.185933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.185933</td>\n",
       "      <td>1.37952</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>2.649913</td>\n",
       "      <td>...</td>\n",
       "      <td>0.65</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>A1LCUPRZ0I8S3I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1OOCYEFLAJD98</th>\n",
       "      <td>0.5116</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.427583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.427583</td>\n",
       "      <td>0.67562</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>2.343953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.60</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>A1OOCYEFLAJD98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1U0FDPQ953KXX</th>\n",
       "      <td>1.1286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>5.252667</td>\n",
       "      <td>3.3118</td>\n",
       "      <td>5.640840</td>\n",
       "      <td>1.30840</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>2.785461</td>\n",
       "      <td>...</td>\n",
       "      <td>0.70</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>A1U0FDPQ953KXX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                demo_arrow_rt  demo_arrow_correct  demo_demo_accuracy  \\\n",
       "A11EXIB1MVBZFJ         1.1560                 1.0            1.000000   \n",
       "A1F9KLZGHE9DTA         0.5979                 1.0            0.833333   \n",
       "A1LCUPRZ0I8S3I         0.9871                 1.0            1.000000   \n",
       "A1OOCYEFLAJD98         0.5116                 1.0            1.000000   \n",
       "A1U0FDPQ953KXX         1.1286                 1.0            0.833333   \n",
       "\n",
       "                demo_RT_overall_mean  demo_RT_incorrect_mean  \\\n",
       "A11EXIB1MVBZFJ             15.790667                     NaN   \n",
       "A1F9KLZGHE9DTA              1.385950                  1.7404   \n",
       "A1LCUPRZ0I8S3I              2.185933                     NaN   \n",
       "A1OOCYEFLAJD98              2.427583                     NaN   \n",
       "A1U0FDPQ953KXX              5.252667                  3.3118   \n",
       "\n",
       "                demo_RT_correct_mean  encoding_arrow_mean_rt  \\\n",
       "A11EXIB1MVBZFJ             15.790667                 1.13860   \n",
       "A1F9KLZGHE9DTA              1.315060                 0.59792   \n",
       "A1LCUPRZ0I8S3I              2.185933                 1.37952   \n",
       "A1OOCYEFLAJD98              2.427583                 0.67562   \n",
       "A1U0FDPQ953KXX              5.640840                 1.30840   \n",
       "\n",
       "                encoding_arrow_accuracy  testing_Test_overall_accuracy  \\\n",
       "A11EXIB1MVBZFJ                      1.0                       0.516667   \n",
       "A1F9KLZGHE9DTA                      1.0                       0.566667   \n",
       "A1LCUPRZ0I8S3I                      1.0                       0.633333   \n",
       "A1OOCYEFLAJD98                      1.0                       0.683333   \n",
       "A1U0FDPQ953KXX                      1.0                       0.683333   \n",
       "\n",
       "                testing_RT_overall_mean  ...  testing_layer_3_accuracy  \\\n",
       "A11EXIB1MVBZFJ                 2.094241  ...                      0.45   \n",
       "A1F9KLZGHE9DTA                 1.418513  ...                      0.45   \n",
       "A1LCUPRZ0I8S3I                 2.649913  ...                      0.65   \n",
       "A1OOCYEFLAJD98                 2.343953  ...                      0.60   \n",
       "A1U0FDPQ953KXX                 2.785461  ...                      0.70   \n",
       "\n",
       "                testing_longest_response_strike  demo_demo_accuracy  \\\n",
       "A11EXIB1MVBZFJ                              4.0                True   \n",
       "A1F9KLZGHE9DTA                              6.0                True   \n",
       "A1LCUPRZ0I8S3I                              4.0                True   \n",
       "A1OOCYEFLAJD98                              4.0                True   \n",
       "A1U0FDPQ953KXX                              3.0                True   \n",
       "\n",
       "                demo_arrow_correct  encoding_arrow_accuracy  \\\n",
       "A11EXIB1MVBZFJ                True                     True   \n",
       "A1F9KLZGHE9DTA                True                     True   \n",
       "A1LCUPRZ0I8S3I                True                     True   \n",
       "A1OOCYEFLAJD98                True                     True   \n",
       "A1U0FDPQ953KXX                True                     True   \n",
       "\n",
       "                testing_longest_response_strike  not_too_slow  not_too_Fast  \\\n",
       "A11EXIB1MVBZFJ                             True          True          True   \n",
       "A1F9KLZGHE9DTA                             True          True          True   \n",
       "A1LCUPRZ0I8S3I                             True          True          True   \n",
       "A1OOCYEFLAJD98                             True          True          True   \n",
       "A1U0FDPQ953KXX                             True          True          True   \n",
       "\n",
       "                sufficient_test_acc        WorkerId  \n",
       "A11EXIB1MVBZFJ                False  A11EXIB1MVBZFJ  \n",
       "A1F9KLZGHE9DTA                False  A1F9KLZGHE9DTA  \n",
       "A1LCUPRZ0I8S3I                 True  A1LCUPRZ0I8S3I  \n",
       "A1OOCYEFLAJD98                 True  A1OOCYEFLAJD98  \n",
       "A1U0FDPQ953KXX                 True  A1U0FDPQ953KXX  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data = pd.concat([data_df_for_analysis,disqualification_df], axis = 1)\n",
    "total_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the final_participants_df and the data_df_for_analysis to disk: \n",
    "final_participants_df.to_csv(PATH_TO_DATA.parent / 'one_line_per_participant_all_info_valid_subjects_only.csv')\n",
    "total_data.to_csv(PATH_TO_DATA.parent / 'one_line_per_participant_all_info_all_subject.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\seaborn\\categorical.py:166: FutureWarning: Setting a gradient palette using color= is deprecated and will be removed in version 0.13. Set `palette='dark:k'` for same effect.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\seaborn\\categorical.py:166: FutureWarning: Setting a gradient palette using color= is deprecated and will be removed in version 0.13. Set `palette='dark:k'` for same effect.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(510.4494949494949, 0.5, 'RT')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig,axes=plt.subplots(nrows=1,ncols=2,figsize=(10,5))\n",
    "sns.barplot(data=final_participants_df[['testing_layer_1_accuracy','testing_layer_2_accuracy','testing_layer_3_accuracy']],ax=axes[0])\n",
    "sns.swarmplot(data=final_participants_df[['testing_layer_1_accuracy','testing_layer_2_accuracy','testing_layer_3_accuracy']],ax=axes[0],color='k')\n",
    "\n",
    "axes[0].set_xticklabels(labels=['layer1','layer2','layer3'],rotation=30)\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "\n",
    "sns.barplot(data=final_participants_df[['testing_layer_1_rt','testing_layer_2_rt','testing_layer_3_rt']],ax=axes[1])\n",
    "sns.swarmplot(data=final_participants_df[['testing_layer_1_rt','testing_layer_2_rt','testing_layer_3_rt']],ax=axes[1],color='k')\n",
    "\n",
    "axes[1].set_xticklabels(labels=['layer1','layer2','layer3'],rotation=30)\n",
    "axes[1].set_ylabel('RT')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'RT')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig,axes=plt.subplots(nrows=1,ncols=2,figsize=(10,5))\n",
    "sns.pointplot(data=final_participants_df[['testing_layer_1_accuracy','testing_layer_2_accuracy','testing_layer_3_accuracy']],ax=axes[0])\n",
    "#sns.swarmplot(data=final_participants_df[['testing_layer_1_accuracy','testing_layer_2_accuracy','testing_layer_3_accuracy']],ax=axes[0],color='k')\n",
    "\n",
    "axes[0].set_xticklabels(labels=['layer1','layer2','layer3'],rotation=30)\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "\n",
    "sns.pointplot(data=final_participants_df[['testing_layer_1_rt','testing_layer_2_rt','testing_layer_3_rt']],ax=axes[1])\n",
    "#sns.swarmplot(data=final_participants_df[['testing_layer_1_rt','testing_layer_2_rt','testing_layer_3_rt']],ax=axes[1],color='k')\n",
    "\n",
    "axes[1].set_xticklabels(labels=['layer1','layer2','layer3'],rotation=30)\n",
    "axes[1].set_ylabel('RT')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changed entrees for: ['A2KDZLWD8RAHDM', 'A3EBIC3PKUSKCL', 'A1PN0EFQD8OHSU', 'A10AKR84P1WXHL', 'A1MT4FMXL4WRAF', 'ABGKJYEITBKIL', 'AL113DDABUJQ0', 'A1CB9NR3SN4VMY', 'A2HY7GQ07YIZTT', 'A1W0K28IND6NR4', 'A2U50SMRZT60ZF', 'A3UZ5V4Y0K3YPV', 'AEHH65WR5E3L6', 'A1SL80AWG592HX', 'A1I1IMZ2ROJY3I', 'A3NME80IO3UFFO', 'A2PTABUVOUYAH5', 'A3USIO03UXTDUT', 'AVP8OEUW3NB4D', 'A1HUQ7QA5QWM5Q', 'A2F5SKVBQQXFX0', 'A3FJQY40AAYLDF', 'A12K1ADYMRSWMJ', 'A1W9HGZ8IKQMTW', 'A5AE8MWFQVBX62', 'ASQJWS2HM0ZW9', 'A5JWBZ2885D1N', 'A14CZ7WXO9TOSX', 'AEOLA4FY5IDHE', 'A2Y8LZS5C81O25', 'AQC0KPAOX4ZPL', 'A3NAONPCTVT6P1', 'A2PF6UAA5SUVD0', 'A290Z6QAL17PQE', 'A2MQPQ30Z0ETL4', 'AG6UL22QLCKOG', 'A29DB0P3TCTY3I', 'A1Y0ZBE9UBJV2S', 'A3Q228ENXTJ38F', 'A1NQVG69U3TRDK', 'A39IAY6VBVR8FD', 'A3JRY3AL756S3P', 'AP9YNGPNQSX7I', 'A29O6FOYRB10S2', 'AUGML2ZY46M47', 'A2HFHW1AT6CYCV', 'A2A66Wjgsvjmdcmc', 'A2BUHMLNE3LUU1']\n"
     ]
    }
   ],
   "source": [
    "#this is the updated shelf: copy from here and place in the shelf location in pavlovia.org\n",
    "new_shelf_dict=shelf_dict.copy()\n",
    "\n",
    "\n",
    "clean_shelf_after_test=True #change to true if you run this code after completing both encoding and test sessions and want to also resert participants that didnt come back at all... \n",
    "if clean_shelf_after_test: \n",
    "\n",
    "\n",
    "    allowed_interval_in_hours=24\n",
    "    allowed_jitter=3\n",
    "    allowed_interval_in_ms=[allowed_interval_in_hours-allowed_jitter,allowed_interval_in_hours+allowed_jitter]*3600*1000\n",
    "\n",
    "\n",
    "    new_shelf_dict=shelf_dict.copy()\n",
    "    changed_keys_list=[]\n",
    "    for key in new_shelf_dict.keys():\n",
    "        cur_entries=new_shelf_dict[key]\n",
    "        if len(cur_entries)==2: \n",
    "            cur_entries[0]=999\n",
    "            changed_keys_list.append(key)\n",
    "\n",
    "        if len(cur_entries)>2:\n",
    "            encoding_time=cur_entries[1]\n",
    "            last_entree=cur_entries[-1]\n",
    "            if (last_entree - encoding_time) < allowed_interval_in_ms[0]:\n",
    "                cur_entries[0]=999\n",
    "                changed_keys_list.append(key)\n",
    "\n",
    "\n",
    "        new_shelf_dict[key]=cur_entries\n",
    "\n",
    "    print('changed entrees for:',changed_keys_list)\n",
    "\n",
    "    ##### print the updated shelf dictionary so you can copy it from the cell output and paste in the shelf:  (change the shelf only if you run this code after both encoding and TEST has ended) ####\n",
    "    new_shelf_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demo_arrow_rt</th>\n",
       "      <th>demo_arrow_correct</th>\n",
       "      <th>demo_demo_accuracy</th>\n",
       "      <th>demo_RT_overall_mean</th>\n",
       "      <th>demo_RT_incorrect_mean</th>\n",
       "      <th>demo_RT_correct_mean</th>\n",
       "      <th>encoding_arrow_mean_rt</th>\n",
       "      <th>encoding_arrow_accuracy</th>\n",
       "      <th>testing_Test_overall_accuracy</th>\n",
       "      <th>testing_RT_overall_mean</th>\n",
       "      <th>testing_RT_incorrect_mean</th>\n",
       "      <th>testing_RT_correct_mean</th>\n",
       "      <th>testing_layer_1_rt</th>\n",
       "      <th>testing_layer_1_accuracy</th>\n",
       "      <th>testing_layer_2_rt</th>\n",
       "      <th>testing_layer_2_accuracy</th>\n",
       "      <th>testing_layer_3_rt</th>\n",
       "      <th>testing_layer_3_accuracy</th>\n",
       "      <th>testing_longest_response_strike</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A1LCUPRZ0I8S3I</th>\n",
       "      <td>0.9871</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.185933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.185933</td>\n",
       "      <td>1.37952</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>2.649913</td>\n",
       "      <td>2.984377</td>\n",
       "      <td>2.456276</td>\n",
       "      <td>2.447855</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.726375</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.775510</td>\n",
       "      <td>0.65</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1OOCYEFLAJD98</th>\n",
       "      <td>0.5116</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.427583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.427583</td>\n",
       "      <td>0.67562</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>2.343953</td>\n",
       "      <td>2.364995</td>\n",
       "      <td>4.215473</td>\n",
       "      <td>2.133665</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.373321</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.526340</td>\n",
       "      <td>0.60</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1U0FDPQ953KXX</th>\n",
       "      <td>1.1286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>5.252667</td>\n",
       "      <td>3.3118</td>\n",
       "      <td>5.640840</td>\n",
       "      <td>1.30840</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>2.785461</td>\n",
       "      <td>2.953126</td>\n",
       "      <td>3.233671</td>\n",
       "      <td>2.932160</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3.165090</td>\n",
       "      <td>0.60</td>\n",
       "      <td>2.231432</td>\n",
       "      <td>0.70</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK4WAT44YKU7J</th>\n",
       "      <td>0.6394</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.239683</td>\n",
       "      <td>2.5745</td>\n",
       "      <td>2.072275</td>\n",
       "      <td>0.52266</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>2.428318</td>\n",
       "      <td>2.267331</td>\n",
       "      <td>2.472847</td>\n",
       "      <td>2.452395</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.254125</td>\n",
       "      <td>0.85</td>\n",
       "      <td>2.578435</td>\n",
       "      <td>0.80</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMEBLCWTZKLS2</th>\n",
       "      <td>0.9730</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.663333</td>\n",
       "      <td>1.3950</td>\n",
       "      <td>1.717000</td>\n",
       "      <td>1.03720</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>2.287683</td>\n",
       "      <td>2.439800</td>\n",
       "      <td>2.179029</td>\n",
       "      <td>2.148400</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.409650</td>\n",
       "      <td>0.55</td>\n",
       "      <td>2.305000</td>\n",
       "      <td>0.45</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATA61WNUAP91U</th>\n",
       "      <td>1.3853</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>2.389683</td>\n",
       "      <td>2.1828</td>\n",
       "      <td>2.431060</td>\n",
       "      <td>1.27288</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>2.547673</td>\n",
       "      <td>2.430700</td>\n",
       "      <td>2.610659</td>\n",
       "      <td>2.755065</td>\n",
       "      <td>0.80</td>\n",
       "      <td>2.373785</td>\n",
       "      <td>0.65</td>\n",
       "      <td>2.514170</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                demo_arrow_rt  demo_arrow_correct  demo_demo_accuracy  \\\n",
       "A1LCUPRZ0I8S3I         0.9871                 1.0            1.000000   \n",
       "A1OOCYEFLAJD98         0.5116                 1.0            1.000000   \n",
       "A1U0FDPQ953KXX         1.1286                 1.0            0.833333   \n",
       "AK4WAT44YKU7J          0.6394                 1.0            0.666667   \n",
       "AMEBLCWTZKLS2          0.9730                 1.0            0.833333   \n",
       "ATA61WNUAP91U          1.3853                 1.0            0.833333   \n",
       "\n",
       "                demo_RT_overall_mean  demo_RT_incorrect_mean  \\\n",
       "A1LCUPRZ0I8S3I              2.185933                     NaN   \n",
       "A1OOCYEFLAJD98              2.427583                     NaN   \n",
       "A1U0FDPQ953KXX              5.252667                  3.3118   \n",
       "AK4WAT44YKU7J               2.239683                  2.5745   \n",
       "AMEBLCWTZKLS2               1.663333                  1.3950   \n",
       "ATA61WNUAP91U               2.389683                  2.1828   \n",
       "\n",
       "                demo_RT_correct_mean  encoding_arrow_mean_rt  \\\n",
       "A1LCUPRZ0I8S3I              2.185933                 1.37952   \n",
       "A1OOCYEFLAJD98              2.427583                 0.67562   \n",
       "A1U0FDPQ953KXX              5.640840                 1.30840   \n",
       "AK4WAT44YKU7J               2.072275                 0.52266   \n",
       "AMEBLCWTZKLS2               1.717000                 1.03720   \n",
       "ATA61WNUAP91U               2.431060                 1.27288   \n",
       "\n",
       "                encoding_arrow_accuracy  testing_Test_overall_accuracy  \\\n",
       "A1LCUPRZ0I8S3I                      1.0                       0.633333   \n",
       "A1OOCYEFLAJD98                      1.0                       0.683333   \n",
       "A1U0FDPQ953KXX                      1.0                       0.683333   \n",
       "AK4WAT44YKU7J                       1.0                       0.783333   \n",
       "AMEBLCWTZKLS2                       1.0                       0.583333   \n",
       "ATA61WNUAP91U                       1.0                       0.650000   \n",
       "\n",
       "                testing_RT_overall_mean  testing_RT_incorrect_mean  \\\n",
       "A1LCUPRZ0I8S3I                 2.649913                   2.984377   \n",
       "A1OOCYEFLAJD98                 2.343953                   2.364995   \n",
       "A1U0FDPQ953KXX                 2.785461                   2.953126   \n",
       "AK4WAT44YKU7J                  2.428318                   2.267331   \n",
       "AMEBLCWTZKLS2                  2.287683                   2.439800   \n",
       "ATA61WNUAP91U                  2.547673                   2.430700   \n",
       "\n",
       "                testing_RT_correct_mean  testing_layer_1_rt  \\\n",
       "A1LCUPRZ0I8S3I                 2.456276            2.447855   \n",
       "A1OOCYEFLAJD98                 4.215473            2.133665   \n",
       "A1U0FDPQ953KXX                 3.233671            2.932160   \n",
       "AK4WAT44YKU7J                  2.472847            2.452395   \n",
       "AMEBLCWTZKLS2                  2.179029            2.148400   \n",
       "ATA61WNUAP91U                  2.610659            2.755065   \n",
       "\n",
       "                testing_layer_1_accuracy  testing_layer_2_rt  \\\n",
       "A1LCUPRZ0I8S3I                      0.75            2.726375   \n",
       "A1OOCYEFLAJD98                      0.75            2.373321   \n",
       "A1U0FDPQ953KXX                      0.75            3.165090   \n",
       "AK4WAT44YKU7J                       0.70            2.254125   \n",
       "AMEBLCWTZKLS2                       0.75            2.409650   \n",
       "ATA61WNUAP91U                       0.80            2.373785   \n",
       "\n",
       "                testing_layer_2_accuracy  testing_layer_3_rt  \\\n",
       "A1LCUPRZ0I8S3I                      0.50            2.775510   \n",
       "A1OOCYEFLAJD98                      0.70            2.526340   \n",
       "A1U0FDPQ953KXX                      0.60            2.231432   \n",
       "AK4WAT44YKU7J                       0.85            2.578435   \n",
       "AMEBLCWTZKLS2                       0.55            2.305000   \n",
       "ATA61WNUAP91U                       0.65            2.514170   \n",
       "\n",
       "                testing_layer_3_accuracy  testing_longest_response_strike  \n",
       "A1LCUPRZ0I8S3I                      0.65                              4.0  \n",
       "A1OOCYEFLAJD98                      0.60                              4.0  \n",
       "A1U0FDPQ953KXX                      0.70                              3.0  \n",
       "AK4WAT44YKU7J                       0.80                              7.0  \n",
       "AMEBLCWTZKLS2                       0.45                              3.0  \n",
       "ATA61WNUAP91U                       0.50                              5.0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_participants_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 were given a UPDATE-completed memory rep, names: ['A15B4KZ3S04HS8', 'A1LA6CIGBNDOH9', 'A22HIX1M4QXZBB', 'A248QG4DPULP46', 'A2J1DNVMJ56JG1', 'A2J57IBR2XIWLS', 'A3MIDLO5S7FU06', 'A3U0GQGAPN2DAV', 'A5P12YJP805RG', 'ASNNAP90D5R1Z', 'A1JJYY622DGE5L', 'AE33JO53WTHZQ', 'A4ANRSA55IW5Q', 'A11EXIB1MVBZFJ', 'AMEBLCWTZKLS2', 'A3EBIC3PKUSKCL', 'AVZRZOK0F26P6', 'A1MT4FMXL4WRAF', 'AK4WAT44YKU7J', 'A3VHDQR8A9JJ4F', 'AL113DDABUJQ0', 'AB8XECKH1JO8P', 'A2HY7GQ07YIZTT', 'A1U0FDPQ953KXX', 'A2M183CETUMR96', 'A1LCUPRZ0I8S3I', 'A3UZ5V4Y0K3YPV', 'ATA61WNUAP91U', 'A149YZJBFRDWBJ', 'A1SL80AWG592HX', 'A1I1IMZ2ROJY3I', 'A3RDT5DH21PVAR', 'A1F9KLZGHE9DTA', 'AVP8OEUW3NB4D', 'A2ASRB2MTHDHPD', 'A1HUQ7QA5QWM5Q', 'A2A66W3JTSP642', 'A98E8M4QLI9RS', 'A3FJQY40AAYLDF', 'A12K1ADYMRSWMJ', 'A31FDAPJJ2EBGA', 'A1W9HGZ8IKQMTW', 'A3JJXDML3XNSQP', 'A1OOCYEFLAJD98', 'A129Y082RKJN6V', 'A2BUHMLNE3LUU0', 'A1NQVG69U3TRDK', 'AUGML2ZY46M47']\n",
      "\n",
      "\n",
      "compy the following dictionary content to the pavlovia dictionary, and to the \"shelf final state.txt\"\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"A1LCUPRZ0I8S3I\": [27, 1667411428866, 1667411954191, 1667491335070], \"A1OOCYEFLAJD98\": [58, 1667414710731, 1667504143232], \"A1U0FDPQ953KXX\": [23, 1667411372469, 1667460670237, 1667486731278, 1667487481938], \"AK4WAT44YKU7J\": [14, 1667410895492, 1667499225041], \"AMEBLCWTZKLS2\": [8, 1667410598167, 1667492835383], \"ATA61WNUAP91U\": [33, 1667411683834, 1667460503131, 1667460556038, 1667474685059, 1667485798828, 1667485989768, 1667486779367, 1667487486096], \"A15B4KZ3S04HS8\": [31, 1667149704730, 1667223830820, 1667239242566], \"A1LA6CIGBNDOH9\": [59, 1667156876722, 1667237966478], \"A22HIX1M4QXZBB\": [19, 1666804285762, 1666882028114], \"A248QG4DPULP46\": [2, 1666796745860, 1666875548743], \"A2J1DNVMJ56JG1\": [22, 1666806879557, 1666887012627], \"A2J57IBR2XIWLS\": [61, 1667171400527, 1667244911656, 1667248541474], \"A3MIDLO5S7FU06\": [7, 1667148924846, 1667227496622], \"A3U0GQGAPN2DAV\": [25, 1667148683750, 1667239544108], \"A5P12YJP805RG\": [1, 1667147891427, 1667216156787, 1667226130459], \"ASNNAP90D5R1Z\": [47, 1667152406322, 1667216854306, 1667237576573]}'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find all participants that exists in the shelf, and make sure they have a participantion code (so they wont be able to come back to this experiemnt)\n",
    "all_shelf_workers_that_are_assigned_participantion=[]\n",
    "for curr_key in shelf_dict.keys():\n",
    "    if curr_key in workers_df['Worker ID'].values:\n",
    "        workers_df.loc[workers_df['Worker ID']==curr_key,qualification_name_for_entire_experiment]=1\n",
    "        all_shelf_workers_that_are_assigned_participantion.append(curr_key)\n",
    "\n",
    "print(f'{len(all_shelf_workers_that_are_assigned_participantion)} were given a {qualification_name_for_entire_experiment}, names: {all_shelf_workers_that_are_assigned_participantion}')\n",
    "\n",
    "#create a new shelf, that only contains the ids and numbers of valid participants (this is so we wont re-use thier custom trials order (csvs))\n",
    "new_shelf_dict=dict()\n",
    "for sub_id in final_participants_df.index: \n",
    "    new_shelf_dict[sub_id]=shelf_dict[sub_id]\n",
    "new_shelf_dict  \n",
    "\n",
    "# add the final state of the previous batch \n",
    "previous_batch = 'batch ' + str(int(batch_name[-1]) - 1)\n",
    "root_dirs = list(PATH_TO_DATA.parent.parent.iterdir())\n",
    "target_dir = PATH_TO_DATA.parent.parent/ previous_batch\n",
    "if target_dir in root_dirs:\n",
    "    path_final_state_shelf = target_dir / 'shelf final state.txt'\n",
    "    with open(path_final_state_shelf) as f:\n",
    "        data = f.read()\n",
    "        shelf_dict = json.loads(data)\n",
    "    \n",
    "    new_shelf_dict = new_shelf_dict | shelf_dict\n",
    "\n",
    "\n",
    "print('\\n\\ncopy the following dictionary content to the pavlovia dictionary, and to the \"shelf final state.txt\"\\n')\n",
    "json.dumps(new_shelf_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_workers_df_extended.to_csv(PATH_TO_DATA.parent / path.Path(batch_name+'_workers_results_extended_with_disqualification.csv'))\n",
    "workers_df.to_csv(PATH_TO_DATA.parent / path.Path(batch_name+'_workers_results_for_upload_after_encoding_and_test.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "23b4a3e8622309bcc6db3d5cc6eb73d60ab98d9ec23bad6a26b709981ccb403a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
