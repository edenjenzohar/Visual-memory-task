{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5dae42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import pathlib as path\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8644109c",
   "metadata": {},
   "source": [
    "# Loading data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4190fa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to pilot folder : this is where the similarity_fungi_all.csv is located\n",
    "PATH_RESULTS_FOLDER = path.Path(r'C:\\Users\\User\\Desktop\\pilot')\n",
    "#path to target images: \n",
    "PATH_TARGET_IMAGES_FOLDER = path.Path(r'C:\\Users\\User\\Desktop\\pilot\\selected_images_best_mean')\n",
    "#path to all images: \n",
    "PATH_ALL_IMAGES_FOLDER=path.Path(r'C:\\Users\\User\\Desktop\\human similarity database\\all images\\DF20_300_manualy_selected\\manualy')\n",
    "#path to save outputs\n",
    "PATH_OUTPUTS=path.Path(r'C:\\Users\\User\\Desktop\\pilot\\Outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9670051",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_df = pd.read_csv(PATH_RESULTS_FOLDER / \"similarity_fungi.csv\")\n",
    "similarity_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c1e1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping only relevent data : image names and similarity across levels \n",
    "similarity_df = similarity_df.drop(['Unnamed: 0','model','category1','category2'], axis = 1)\n",
    "similarity_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaba19e",
   "metadata": {},
   "source": [
    "# Experimental Setup Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0353d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the levels you want to average over in each sub list. The first sublist ['level_0','level_1'] is the layers \n",
    "# we wish to average over to get the lower layers average similarity. The same goes for the second and third sublist. \n",
    "levels = [['level_0'],['level_1','level_2','level_3'],['level_4','level_5','level_6']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933d4353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these parameters are for the second part of the notetbook where we create\n",
    "# the actual trials from the experimental setup table\n",
    "number_subjects_each_image = 10\n",
    "total_number_levels = 3 \n",
    "number_target_images = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caec4c7",
   "metadata": {},
   "source": [
    "### Loading the selected images data and saving names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f775da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading images from sub folders and saving the image names in a list \"selected_images\"\n",
    "# the selected images are .jpg but the image names in similarity df are .pkl \n",
    "# so we will change all names to pkl\n",
    "selected_images_paths = list(PATH_TARGET_IMAGES_FOLDER.glob(\"*/*.jpg\"))\n",
    "selected_images = [image.name.replace('.jpg','.pkl') for image in selected_images_paths]\n",
    "\n",
    "print(f'The total number of selected images is : {len(selected_images)}')\n",
    "print('The selected images names look like:')\n",
    "print(selected_images[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605e9a8c",
   "metadata": {},
   "source": [
    "# PART 1 : Creating experimental setup table\n",
    "#### For each selected image, we find the most similar image on average from the specified sublayers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92779c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_matches_0 = []\n",
    "layer_matches_1 = []\n",
    "layer_matches_2 = []\n",
    "selected_matches = []\n",
    "\n",
    "for target_image in selected_images:\n",
    "    # list of other selected images \n",
    "    other_images = [x for x in selected_images if x != target_image]\n",
    "    # keeping only relevent rows with target image \n",
    "    current_image_df = similarity_df[(similarity_df['image1'] == target_image) | (similarity_df['image2'] == target_image)]\n",
    "    \n",
    "    # removing rows with similarity to other target images \n",
    "    for image in other_images:\n",
    "        idx_image1 = current_image_df['image1'] == image\n",
    "        idx_image2 = current_image_df['image2'] == image\n",
    "        total_idx = idx_image1 + idx_image2\n",
    "        current_image_df = current_image_df.drop(total_idx[total_idx == True].index, axis = 0)\n",
    "        \n",
    "    # removing rows with similarity to matched images that already have been picked \n",
    "    for image in selected_matches:\n",
    "        idx_image1 = current_image_df['image1'] == image\n",
    "        idx_image2 = current_image_df['image2'] == image\n",
    "        total_idx = idx_image1 + idx_image2\n",
    "        current_image_df = current_image_df.drop(total_idx[total_idx == True].index, axis = 0)\n",
    "        \n",
    "    \n",
    "    for idx,level in enumerate(levels):\n",
    "        # finding max similarity row\n",
    "        best_trial = current_image_df.loc[np.mean(current_image_df[level], axis = 1).idxmax()]\n",
    "        # saving name of pair image (it can be in one of the two columns)\n",
    "        if best_trial['image1'] != target_image:\n",
    "            image_name = best_trial['image1']\n",
    "        else: \n",
    "            image_name = best_trial['image2']\n",
    "        \n",
    "        selected_matches.append(image_name)\n",
    "        # appending to relevent list \n",
    "        if idx == 0:\n",
    "            layer_matches_0.append(image_name)\n",
    "        elif idx == 1:\n",
    "            layer_matches_1.append(image_name)\n",
    "        elif idx ==2:\n",
    "            layer_matches_2.append(image_name)\n",
    "            \n",
    "        # dropping matched image so it cant be picked again \n",
    "        current_image_df = current_image_df.drop(best_trial.name, axis = 0)\n",
    "\n",
    "        \n",
    "experiment_setup_df = pd.DataFrame(list(zip(selected_images,layer_matches_0,layer_matches_1,layer_matches_2)),columns = ['target_image','layer1','layer2','layer3'])\n",
    "experiment_setup_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ada5cee",
   "metadata": {},
   "source": [
    "## Lets have a look at the pairs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842cc84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images_with_distractors_for_pilot(experiment_setup_df,PATH_TARGET_IMAGES_FOLDER,PATH_OUTPUTS,ncols=4,nrows=20,im_range=np.arange(0,20),fig_name='default'):\n",
    "    allimages_list=list(PATH_TARGET_IMAGES_FOLDER.rglob('*.jpg'))\n",
    "    allimages_list_namesonly=[img.name for img in allimages_list]\n",
    "\n",
    "    ncols=4\n",
    "    nrows=20\n",
    "    # TODO: add a function to look at the selected pairs when you have all images in folder \n",
    "    fig,axes=plt.subplots(nrows=nrows,ncols=ncols,figsize=(ncols*2*2,nrows*2*2),sharex=True,sharey=True,gridspec_kw = {'wspace':0.2, 'hspace':0})\n",
    "    fig.patch.set_facecolor('white')\n",
    "    cnt=0\n",
    "    for im_ind in im_range:\n",
    "        cur_img=experiment_setup_df.iloc[im_ind]['target_image']\n",
    "        cur_img_jpg=cur_img.replace('.pkl','.jpg')\n",
    "        im_index=allimages_list_namesonly.index(cur_img_jpg)\n",
    "        cur_img_jpg=allimages_list[im_index]\n",
    "        l1_img=PATH_ALL_IMAGES_FOLDER / experiment_setup_df.iloc[im_ind]['layer1'].replace('.pkl','.jpg')\n",
    "        l2_img=PATH_ALL_IMAGES_FOLDER / experiment_setup_df.iloc[im_ind]['layer2'].replace('.pkl','.jpg')\n",
    "        l3_img=PATH_ALL_IMAGES_FOLDER / experiment_setup_df.iloc[im_ind]['layer3'].replace('.pkl','.jpg')\n",
    "\n",
    "        cur_img_jpg=Image.open(cur_img_jpg)\n",
    "        axes[cnt,0].imshow(cur_img_jpg)\n",
    "        axes[cnt,0].set_title(experiment_setup_df.iloc[im_ind]['target_image'].replace('.pkl',''),color='k')\n",
    "        l1_img=Image.open(l1_img)\n",
    "        axes[cnt,1].imshow(l1_img)\n",
    "        axes[cnt,1].set_title(experiment_setup_df.iloc[im_ind]['layer1'].replace('.pkl',''),color='k')\n",
    "        l2_img=Image.open(l2_img)\n",
    "        axes[cnt,2].imshow(l2_img)\n",
    "        axes[cnt,2].set_title(experiment_setup_df.iloc[im_ind]['layer2'].replace('.pkl',''),color='k')\n",
    "        l3_img=Image.open(l3_img)\n",
    "        axes[cnt,3].imshow(l3_img)\n",
    "        axes[cnt,3].set_title(experiment_setup_df.iloc[im_ind]['layer3'].replace('.pkl',''),color='k')\n",
    "\n",
    "        axes[cnt,0].set_xticks([])\n",
    "        axes[cnt,0].set_yticks([])\n",
    "\n",
    "        cnt=cnt+1\n",
    "    #save the figure: \n",
    "    svg_name=fig_name + '.svg'\n",
    "    png_name=fig_name + '.png'\n",
    "\n",
    "    fig.savefig(PATH_OUTPUTS / svg_name,format='svg',bbox_inches='tight')\n",
    "    fig.savefig(PATH_OUTPUTS / png_name,format='png',bbox_inches='tight')\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfdc039",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig1=plot_images_with_distractors_for_pilot(experiment_setup_df,PATH_TARGET_IMAGES_FOLDER,PATH_OUTPUTS,ncols=4,nrows=20,im_range=np.arange(0,20),fig_name='all_layer1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda9bb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2=plot_images_with_distractors_for_pilot(experiment_setup_df,PATH_TARGET_IMAGES_FOLDER,PATH_OUTPUTS,ncols=4,nrows=20,im_range=np.arange(20,40),fig_name='all_layer2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2323d22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3=plot_images_with_distractors_for_pilot(experiment_setup_df,PATH_TARGET_IMAGES_FOLDER,PATH_OUTPUTS,ncols=4,nrows=20,im_range=np.arange(40,60),fig_name='all_layer3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300505c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TODO: #allow to insert a list of bad distractor images and replace them: \n",
    "\n",
    "#get a list of \"bad\" distractors: remove them and replace with the second best matches.\n",
    "bad_distractors=['2238482279-94198','2868474407-362883']\n",
    "\n",
    "\n",
    "layer_cols=[col for col in experiment_setup_df.columns if 'layer' in col]\n",
    "for layer in layer_cols:\n",
    "    location=np.where(experiment_setup_df[layer].str.contains('2238482279-94198', na=True))[0]\n",
    "    if not len(location)==0:\n",
    "        print(location[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396cdff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_df.mean().T.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0fc292",
   "metadata": {},
   "source": [
    "# PART 2 : Creating the experiment setup trials from table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb51b986",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_setup_df_dup = pd.DataFrame(np.repeat(experiment_setup_df.values, number_subjects_each_image*total_number_levels, axis=0),columns = experiment_setup_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75572cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_trials_pool = pd.DataFrame()\n",
    "id_1 = 0 \n",
    "layer_id = 1\n",
    "\n",
    "for i in range(len(selected_images)*len(levels)):\n",
    "    # name of current layer\n",
    "    layer_name = 'layer'+str(layer_id)\n",
    "    # upper index\n",
    "    id_2 = id_1 + 10 \n",
    "    # current section of data frame\n",
    "    temp_df = experiment_setup_df_dup.iloc[id_1:id_2][['target_image',f'{layer_name}']]\n",
    "    # adding layer column \n",
    "    temp_df['layer'] = layer_id \n",
    "    # re naming column for concat\n",
    "    temp_df = temp_df.rename({f'{layer_name}': 'pair'}, axis='columns')\n",
    "    # concatinating \n",
    "    total_trials_pool = pd.concat([total_trials_pool,temp_df], axis = 0)\n",
    "    \n",
    "    # updating id \n",
    "    id_1 = id_2\n",
    "    id_2 = id_2 + 10\n",
    "    # updating layer name \n",
    "    if layer_id == 3:\n",
    "        layer_id = 1 \n",
    "    else: \n",
    "        layer_id +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44607f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_trials_pool.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c9ca1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_trials_pool = pd.DataFrame(data = [target,pair,pair],columns = ['target_image','pair','layer'])\n",
    "total_trials_pool.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343e0cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_dict = {}\n",
    "for subject in range(1): # number_subjects_each_image*total_number_levels*number_target_images):\n",
    "    \n",
    "    # creating the encoding csv \n",
    "    subject_df = total_trials_pool.copy()\n",
    "    sub_encoding_trials_df = pd.DataFrame()\n",
    "    while len(subject_df)>0:\n",
    "        \n",
    "        id = np.random.choice(len(subject_df))\n",
    "        random_trial = subject_df.iloc[id]\n",
    "        # adding random trial to subject trials \n",
    "        sub_encoding_trials_df = pd.concat([sub_encoding_trials_df,random_trial], axis = 1)\n",
    "        \n",
    "        #counting in dict \n",
    "        key_name =  random_trial['target_image'] + '-' + random_trial['pair'] \n",
    "        if key_name in counter_dict:\n",
    "            counter_dict[key_name] +=1\n",
    "        else:\n",
    "            counter_dict[key_name] = 1\n",
    "        \n",
    "        \n",
    "        # removing trial from total trial pool \n",
    "        total_trials_pool = total_trials_pool.drop(random_trial.name, axis = 0)\n",
    "        \n",
    "        # removing all trials with selected image \n",
    "        subject_df = subject_df.drop(subject_df[subject_df['target_image'] == random_trial['target_image']].index, axis = 0)\n",
    "         \n",
    "    \n",
    "    sub_encoding_trials_df = sub_encoding_trials_df.T.reset_index(drop=True)\n",
    "    # creating the test csv, before adding the arrow trials - not relevent for test phase\n",
    "    sub_test_trials_df = sub_encoding_trials_df.copy()\n",
    "    \n",
    "    # adding correct colomn with none for all images \n",
    "    sub_encoding_trials_df['correct'] = None\n",
    "    # inserting random arrows - left and right every 14 images\n",
    "    top_idx = [13,28,43,57]\n",
    "    random_noise = [0,1,2,-2,-1]\n",
    "    arrows = ['right.png','left.png']\n",
    "\n",
    "    for arrow in range(len(top_idx)):\n",
    "        chosen_noise = random.choice(random_noise)\n",
    "        print(chosen_noise)\n",
    "        chosen_arrow = random.choice(arrows)\n",
    "        print(chosen_arrow)\n",
    "        chosen_idx = top_idx[arrow] + chosen_noise - 0.5\n",
    "        print(chosen_idx)\n",
    "        correct = chosen_arrow.split('.')[0]\n",
    "        print(correct)\n",
    "\n",
    "        new_row = [chosen_arrow, None, None,correct]\n",
    "\n",
    "\n",
    "        # adding row \n",
    "        sub_encoding_trials_df.loc[chosen_idx] = new_row\n",
    "        sub_encoding_trials_df = sub_encoding_trials_df.sort_index().reset_index(drop=True)\n",
    "        \n",
    "    # saving to csv - commenting for now.. \n",
    "    sub_encoding_trials_df.to_csv(f'sub_encoding{subject}.csv', index=False)\n",
    "    \n",
    "    \n",
    "   \n",
    "    correct_column = []\n",
    "\n",
    "    for row in sub_test_trials_df.T:\n",
    "        random_pick = np.random.randint(0,2)\n",
    "\n",
    "        if random_pick == 0:\n",
    "            correct_column.append('left')\n",
    "        elif random_pick == 1:\n",
    "            sub_test_trials_df.loc[row,['target_image','pair']] = sub_test_trials_df.loc[row,['pair','target_image']].values\n",
    "\n",
    "            correct_column.append('right')\n",
    "\n",
    "    sub_test_trials_df['correct'] = correct_column\n",
    "    sub_test_trials_df.columns = ['image1', 'image2', 'layer', 'correct']\n",
    "\n",
    "    sub_test_trials_df.to_csv(f'sub_test{subject}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7795b484",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The total trials for each combination is:') \n",
    "# Iterate over key/value pairs in dict and print them\n",
    "for key, value in counter_dict.items():\n",
    "    print(key, ' : ', value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "f08154012ddadd8e950e6e9e035c7a7b32c136e7647e9b7c77e02eb723a8bedb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
